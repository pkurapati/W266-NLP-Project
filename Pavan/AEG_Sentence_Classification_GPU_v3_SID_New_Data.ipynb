{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import json, os, re, shutil, sys, time\n",
    "import seaborn as sns\n",
    "from importlib import reload\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "from collections import defaultdict\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Import spacy\n",
    "import spacy\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NumPy, Pandas and TensorFlow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from numpy.random import seed\n",
    "from pandas import read_csv, DataFrame\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Activation, Dropout, Conv1D, MaxPooling1D, Bidirectional, Flatten, TimeDistributed\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import keras.backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEG Long Essay Sentence Level Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12976, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "aeg_long = pd.read_csv(\"../data-DNC/AEG/training_set_rel3.tsv\",sep='\\t',encoding = \"latin1\")\n",
    "aeg_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test. We need to do this first to ensure that when we split to \n",
    "# sentence level, we have sentences of a given essay in either training or test but not on both.\n",
    "\n",
    "train_comb,test_comb = train_test_split(aeg_long,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10380, 5)\n",
      "(2596, 5)\n",
      "[ 3567  4233  6518 15174 18855]\n",
      "[ 9908  9872   305 12771  6839]\n"
     ]
    }
   ],
   "source": [
    "# Create train and test data frames with relevant fields\n",
    "\n",
    "x_train_df = train_comb.filter(['essay_id','essay_set','essay','domain1_score'], axis=1)\n",
    "x_test_df = test_comb.filter(['essay_id','essay_set','essay','domain1_score'], axis=1)\n",
    "\n",
    "x_train_df = x_train_df.reset_index()\n",
    "x_test_df = x_test_df.reset_index()\n",
    "print(x_train_df.shape)\n",
    "print(x_test_df.shape)\n",
    "print(x_train_df.essay_id[:5].values)\n",
    "print(x_test_df.essay_id[:5].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split essay into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use spacy to split the essay into sentences. \n",
    "# Load spacy large english module\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to split essay into sentences\n",
    "def create_sentences_df(df):\n",
    "    \"\"\" Function to split essay data into individual sentences. Returns a dataframe\"\"\"\n",
    "    start=datetime.now()\n",
    "    aeg_long_sentence = pd.DataFrame(columns=['essay_id','essay_set','sentence','domain1_score'])\n",
    "    for i in range(len(df)):\n",
    "        if i%1000 == 0:\n",
    "            print(\"At iteration :\",i)\n",
    "            print(\"Duration: \",datetime.now()-start)\n",
    "        sentence = nlp(df.essay[i])\n",
    "        for s in sentence.sents:\n",
    "            aeg_long_sentence = aeg_long_sentence.append({'essay_id' : df.essay_id[i],\n",
    "                                                          'essay_set' : df.essay_set[i],'sentence' : s.text, \n",
    "                                                          'domain1_score' : df.domain1_score[i]},\n",
    "                                                         ignore_index=True)\n",
    "    return aeg_long_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration : 0\n",
      "Duration:  0:00:00.001094\n",
      "At iteration : 1000\n",
      "Duration:  0:01:13.910230\n",
      "At iteration : 2000\n",
      "Duration:  0:02:41.471731\n",
      "At iteration : 3000\n",
      "Duration:  0:04:57.690647\n",
      "At iteration : 4000\n",
      "Duration:  0:07:51.580886\n",
      "At iteration : 5000\n",
      "Duration:  0:11:39.480142\n",
      "At iteration : 6000\n",
      "Duration:  0:16:11.116163\n",
      "At iteration : 7000\n",
      "Duration:  0:21:46.361166\n",
      "At iteration : 8000\n",
      "Duration:  0:27:57.529110\n",
      "At iteration : 9000\n",
      "Duration:  0:34:42.670452\n",
      "At iteration : 10000\n",
      "Duration:  0:42:12.653912\n"
     ]
    }
   ],
   "source": [
    "# Split train data into sentences\n",
    "x_train_sentence_df = create_sentences_df(x_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration : 0\n",
      "Duration:  0:00:00.001098\n",
      "At iteration : 1000\n",
      "Duration:  0:01:15.384433\n",
      "At iteration : 2000\n",
      "Duration:  0:02:53.557499\n"
     ]
    }
   ],
   "source": [
    "# Split test data into sentences\n",
    "x_test_sentence_df = create_sentences_df(x_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each essay set has a different scoring range. We need to normalize the scores to a standard scale for training.\n",
    "def normalize_score(essay):\n",
    "    \"\"\" Normalizes the domain score based on percentage\"\"\"\n",
    "    score = 0\n",
    "    score = float(essay[3])\n",
    "    essay_set = essay[1]\n",
    "    if essay_set == 1:\n",
    "        div = 12\n",
    "    elif essay_set == 2:\n",
    "        div = 5\n",
    "    elif essay_set == 3:\n",
    "        div = 3\n",
    "    elif essay_set == 4:\n",
    "        div = 3\n",
    "    elif essay_set == 5:\n",
    "        div = 4\n",
    "    elif essay_set == 6:\n",
    "        div = 4\n",
    "    elif essay_set == 7:\n",
    "        div = 25\n",
    "    elif essay_set == 8:\n",
    "        div = 50\n",
    "    return score/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_sentence_df['Norm_Score'] = x_train_sentence_df.apply(normalize_score,axis=1)\n",
    "x_test_sentence_df['Norm_Score'] = x_test_sentence_df.apply(normalize_score,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>sentence</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>Norm_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4075</td>\n",
       "      <td>2</td>\n",
       "      <td>Did your child ever bring home a book?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4075</td>\n",
       "      <td>2</td>\n",
       "      <td>A piece of music, movie or magazine?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4075</td>\n",
       "      <td>2</td>\n",
       "      <td>Did you ever stop to think that the piece of i...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4075</td>\n",
       "      <td>2</td>\n",
       "      <td>There are points in time where there isn't an ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4075</td>\n",
       "      <td>2</td>\n",
       "      <td>The driving question is do you want to remove ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id essay_set                                           sentence  \\\n",
       "0     4075         2             Did your child ever bring home a book?   \n",
       "1     4075         2               A piece of music, movie or magazine?   \n",
       "2     4075         2  Did you ever stop to think that the piece of i...   \n",
       "3     4075         2  There are points in time where there isn't an ...   \n",
       "4     4075         2  The driving question is do you want to remove ...   \n",
       "\n",
       "   domain1_score  Norm_Score  \n",
       "0            3.0         0.6  \n",
       "1            3.0         0.6  \n",
       "2            3.0         0.6  \n",
       "3            3.0         0.6  \n",
       "4            3.0         0.6  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sentence_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store this dataset in pickle format so that we don't have to redo the above steps.\n",
    "x_train_sentence_df.to_pickle(\"./x_train_sentence_df.pkl\")\n",
    "x_test_sentence_df.to_pickle(\"./x_test_sentence_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147123, 5)\n",
      "(36778, 5)\n"
     ]
    }
   ],
   "source": [
    "# Open the pickled version\n",
    "x_train_sentence_df = pd.read_pickle(\"/home/pkurapati/x_train_sentence_df.pkl\")\n",
    "x_test_sentence_df = pd.read_pickle(\"/home/pkurapati/x_test_sentence_df.pkl\")\n",
    "print(x_train_sentence_df.shape)\n",
    "print(x_test_sentence_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_sentence(sid,sentence):\n",
    "    sentence = sid_dict[sid] + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_dict = {1:\"One. \",2:\"Two. \",3:\"Three. \",4:\"Four. \",5:\"Five \",6:\"Six. \",7:\"Seven. \",8:\"Eight. \"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sentence_df['mod_sentence'] = np.vectorize(append_sentence)(x_train_sentence_df['essay_set'],\n",
    "                                                                    x_train_sentence_df['sentence'])\n",
    "\n",
    "x_test_sentence_df['mod_sentence'] = np.vectorize(append_sentence)(x_test_sentence_df['essay_set'],\n",
    "                                                                    x_test_sentence_df['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>sentence</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>Norm_Score</th>\n",
       "      <th>mod_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3567</td>\n",
       "      <td>2</td>\n",
       "      <td>There are many types of reading materials for ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Two. There are many types of reading materials...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3567</td>\n",
       "      <td>2</td>\n",
       "      <td>You can find things on cars, trucks, sports, a...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Two. You can find things on cars, trucks, spor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3567</td>\n",
       "      <td>2</td>\n",
       "      <td>There are some materials in a library though t...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Two. There are some materials in a library tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3567</td>\n",
       "      <td>2</td>\n",
       "      <td>But should those materials be removed from the...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Two. But should those materials be removed fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3567</td>\n",
       "      <td>2</td>\n",
       "      <td>Some think that they should and others think t...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Two. Some think that they should and others th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id essay_set                                           sentence  \\\n",
       "0     3567         2  There are many types of reading materials for ...   \n",
       "1     3567         2  You can find things on cars, trucks, sports, a...   \n",
       "2     3567         2  There are some materials in a library though t...   \n",
       "3     3567         2  But should those materials be removed from the...   \n",
       "4     3567         2  Some think that they should and others think t...   \n",
       "\n",
       "  domain1_score  Norm_Score                                       mod_sentence  \n",
       "0             4         0.8  Two. There are many types of reading materials...  \n",
       "1             4         0.8  Two. You can find things on cars, trucks, spor...  \n",
       "2             4         0.8  Two. There are some materials in a library tho...  \n",
       "3             4         0.8  Two. But should those materials be removed fro...  \n",
       "4             4         0.8  Two. Some think that they should and others th...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sentence_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147123,)\n",
      "(147123,)\n",
      "(36778,)\n",
      "(36778,)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test text and labels\n",
    "\n",
    "x_train = x_train_sentence_df['mod_sentence'].values\n",
    "y_train = x_train_sentence_df['Norm_Score'].values\n",
    "x_test = x_test_sentence_df['mod_sentence'].values\n",
    "y_test = x_test_sentence_df['Norm_Score'].values\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "train_data = pad_sequences(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_class = train_data.shape[1]\n",
    "max_words_class = vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36778, 176)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "test_data = pad_sequences(test_seq, maxlen=max_len_class)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1917494 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('/home/pkurapati/W266-NLP-Project/data-DNC/glove.42B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocabulary_size, 300))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(actual, predict):\n",
    "    diff = actual - predict\n",
    "    diff = sum(diff**2) / len(actual)\n",
    "    return np.sqrt(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definitions\n",
    "\n",
    "def FF_NN():\n",
    "    \"\"\" Simple feed forward NN\"\"\"\n",
    "    model_ff = Sequential()\n",
    "    model_ff.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], trainable=False))\n",
    "    model_ff.add(tf.keras.layers.Flatten())\n",
    "    model_ff.add(tf.keras.layers.Dense(50,activation='tanh'))\n",
    "    model_ff.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_ff.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "    model_ff.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_ff\n",
    "\n",
    "def GRU():\n",
    "    \"\"\" Gated Recurrent Unit\"\"\"\n",
    "    model_gru = Sequential()\n",
    "    model_gru.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], trainable=False))\n",
    "    model_gru.add(tf.keras.layers.GRU(32,activation='tanh'))\n",
    "    model_gru.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_gru.add(tf.keras.layers.Dense(1,name='out_layer'))\n",
    "    model_gru.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_gru\n",
    "\n",
    "def CNN_FF():\n",
    "    \"\"\" CNN with Feed Forward NN \"\"\"\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], trainable=False))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_conv.add(tf.keras.layers.Conv1D(64, 5, activation='relu'))\n",
    "    model_conv.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "    model_conv.add(tf.keras.layers.Dense(100))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_conv.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    model_conv.compile(loss = 'mse', optimizer = tf.train.AdamOptimizer(), metrics = ['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "def CNN_lstm():\n",
    "    \"\"\" CNN with single layer LSTM & Feed Forward NN\"\"\"\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], trainable=False))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_conv.add(tf.keras.layers.Conv1D(64, 5, activation='relu'))\n",
    "    model_conv.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "    model_conv.add(tf.keras.layers.LSTM(100))\n",
    "    model_conv.add(tf.keras.layers.Dense(100))\n",
    "    model_conv.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    model_conv.compile(loss = 'mse', optimizer = tf.train.AdamOptimizer(), metrics = ['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "def stack_lstm():\n",
    "    \"\"\" Three layered stacked LSTM.\"\"\"\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], trainable=False))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32,return_sequences=True))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32, return_sequences=True))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.2))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32))\n",
    "    model_conv.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    model_conv.compile(loss = 'mse', optimizer = tf.train.AdamOptimizer(), metrics = ['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "def stateful_stacked_lstm():\n",
    "    # In stateful, total samples needs to be divisible by batch size\n",
    "    # we have 147026 samples, so selecting 6683 (6683*22=147026)\n",
    "    # The test sample need to be a multiple of 6683 as well\n",
    "    batch_size=2\n",
    "    model_conv = Sequential()\n",
    "    # In stateful, we have to pass batch_input_shape to the first layer\n",
    "    model_conv.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], \n",
    "                                             trainable=False,batch_input_shape=(batch_size,max_len_class)))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32,stateful=True,return_sequences=True))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_conv.add(tf.keras.layers.Dense(100))\n",
    "    model_conv.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    #sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "    model_conv.compile(loss = 'mse', optimizer = tf.train.AdamOptimizer(), metrics = ['accuracy'])\n",
    "    #model_conv.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_conv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get the multiplication factor. We can get it back from the essay set, but\n",
    "# it is better to do it from the score, because there are scores with value 0, and its MF should be 0\n",
    "\n",
    "def find_mult_factor(x):\n",
    "    \"\"\" Function to find the multiplication factor for denormalizing\"\"\"\n",
    "    if x[1] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.around(x[0]/x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(x):\n",
    "    \"\"\" Function to Denormalize the score\"\"\"\n",
    "    return np.around(x[2] * x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_min_mean_score(df):\n",
    "    \"\"\" Function to find the max, min and rounded mean of sentence scores\"\"\"\n",
    "    new_df = pd.DataFrame(columns=['essay_id','essay_set','Orig_Score','Max_Score','Min_Score','Mean_Score'])\n",
    "    essay_ids = np.unique(df.essay_id)\n",
    "    for e_id in essay_ids:\n",
    "        df_temp = df[df.essay_id == e_id]\n",
    "        max_score = np.max(df_temp.pred_score)\n",
    "        min_score = np.min(df_temp.pred_score)\n",
    "        # we need to round the mean so that kappa score doesnt complain\n",
    "        mean_score = np.around(np.mean(df_temp.pred_score))\n",
    "        new_df = new_df.append({'essay_id':e_id,'essay_set':int(np.unique(df_temp.essay_set)),\n",
    "                                'Orig_Score':int(np.unique(df_temp.orig_score)),'Max_Score':max_score,\n",
    "                                'Min_Score':min_score,'Mean_Score':mean_score},ignore_index=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the per essay set scores\n",
    "\n",
    "def essay_set_metrics(df):\n",
    "    \"\"\" Calculate per essay set metrics\"\"\"\n",
    "    set_df = pd.DataFrame(columns=['essay_set','RMSE','Kappa','Accuracy'])\n",
    "    e_sets = np.unique(df.essay_set)\n",
    "    for e_s in e_sets:\n",
    "        df_s = df[df.essay_set == e_s]\n",
    "        original_score = df_s.Orig_Score.values.astype(int)\n",
    "        predicted_score = df_s.Mean_Score.values.astype(int)\n",
    "        rmse = RMSE(original_score,predicted_score)\n",
    "        kappa = cohen_kappa_score(original_score,predicted_score)\n",
    "        accuracy = accuracy_score(original_score,predicted_score)\n",
    "        set_df = set_df.append({'essay_set':e_s,'RMSE':rmse,'Kappa':kappa,'Accuracy':accuracy},\n",
    "                              ignore_index=True)\n",
    "    return set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_count(df):\n",
    "    \"\"\" Returns the number of sentences in an essay \"\"\"\n",
    "    essay_count = df.groupby('essay_id').count()\n",
    "    essay_count = essay_count.drop(['sentence','domain1_score','Norm_Score'],axis=1)\n",
    "    essay_count.columns = ['Number_of_Sentences']\n",
    "    return essay_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "147123/147123 [==============================] - 45s 307us/step - loss: 0.0345 - acc: 0.0976\n",
      "Epoch 2/20\n",
      "147123/147123 [==============================] - 27s 186us/step - loss: 0.0273 - acc: 0.0997\n",
      "Epoch 3/20\n",
      "147123/147123 [==============================] - 27s 184us/step - loss: 0.0262 - acc: 0.1006\n",
      "Epoch 4/20\n",
      "147123/147123 [==============================] - 27s 186us/step - loss: 0.0255 - acc: 0.1012\n",
      "Epoch 5/20\n",
      "147123/147123 [==============================] - 28s 190us/step - loss: 0.0247 - acc: 0.1016\n",
      "Epoch 6/20\n",
      "147123/147123 [==============================] - 27s 185us/step - loss: 0.0240 - acc: 0.1021\n",
      "Epoch 7/20\n",
      "147123/147123 [==============================] - 27s 184us/step - loss: 0.0234 - acc: 0.1025\n",
      "Epoch 8/20\n",
      "147123/147123 [==============================] - 28s 187us/step - loss: 0.0227 - acc: 0.1028\n",
      "Epoch 9/20\n",
      "147123/147123 [==============================] - 27s 185us/step - loss: 0.0221 - acc: 0.1031\n",
      "Epoch 10/20\n",
      "147123/147123 [==============================] - 27s 186us/step - loss: 0.0215 - acc: 0.1034\n",
      "Epoch 11/20\n",
      "147123/147123 [==============================] - 27s 185us/step - loss: 0.0210 - acc: 0.1035\n",
      "Epoch 12/20\n",
      "147123/147123 [==============================] - 27s 184us/step - loss: 0.0205 - acc: 0.1038\n",
      "Epoch 13/20\n",
      "147123/147123 [==============================] - 27s 185us/step - loss: 0.0201 - acc: 0.1039\n",
      "Epoch 14/20\n",
      "147123/147123 [==============================] - 27s 186us/step - loss: 0.0195 - acc: 0.1041\n",
      "Epoch 15/20\n",
      "147123/147123 [==============================] - 28s 187us/step - loss: 0.0193 - acc: 0.1042\n",
      "Epoch 16/20\n",
      "147123/147123 [==============================] - 27s 186us/step - loss: 0.0190 - acc: 0.1043\n",
      "Epoch 17/20\n",
      "147123/147123 [==============================] - 28s 189us/step - loss: 0.0185 - acc: 0.1044\n",
      "Epoch 18/20\n",
      "147123/147123 [==============================] - 28s 188us/step - loss: 0.0182 - acc: 0.1043\n",
      "Epoch 19/20\n",
      "147123/147123 [==============================] - 27s 186us/step - loss: 0.0182 - acc: 0.1044\n",
      "Epoch 20/20\n",
      "147123/147123 [==============================] - 27s 186us/step - loss: 0.0178 - acc: 0.1045\n",
      "RMSE before denormalizing:  0.1718188190244541\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict\n",
    "estimator = KerasRegressor(build_fn=CNN_lstm, epochs=20, batch_size=500)\n",
    "estimator.fit(train_data, y_train)\n",
    "prediction_cnn_glove=estimator.predict(test_data)\n",
    "# Metric before denormalizing. This is not very useful as the scale per essay set is different\n",
    "rmse_val = RMSE(y_test,prediction_cnn_glove)\n",
    "print(\"RMSE before denormalizing: \",rmse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.6789887651390716\n",
      "Cohen Kappa:  0.26229815533140743\n",
      "Accuracy:  0.32359018978737286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Denormalize\n",
    "\n",
    "# Construct pandas data frame of scores of each sentences\n",
    "cnn_df = pd.DataFrame([x_test_sentence_df['domain1_score'].astype(np.double), y_test.astype(np.double),\n",
    "                      prediction_cnn_glove.astype(np.double)]).transpose()\n",
    "cnn_df.columns = ['Orig_Score','Norm_Score','Pred_Score']\n",
    "# Find Multiplication factor using the function we defined before\n",
    "cnn_df['Mult_Factor'] = cnn_df.apply(find_mult_factor,axis=1)\n",
    "cnn_df['Denorm_Pred_Score'] = cnn_df.apply(denormalize,axis=1)\n",
    "\n",
    "# Extract the scores of each sentences\n",
    "orig_score = cnn_df.Orig_Score.as_matrix(columns=None)\n",
    "orig_score = orig_score.astype(np.int)\n",
    "pred_score = cnn_df.Denorm_Pred_Score.as_matrix(columns=None)\n",
    "pred_score = pred_score.astype(np.int)\n",
    "rmse_cnn = RMSE(orig_score,pred_score)\n",
    "\n",
    "# Provide the metrics at sentence level\n",
    "print(\"RMSE: \",rmse_cnn)\n",
    "cohen_kappa = cohen_kappa_score(orig_score,pred_score)\n",
    "print(\"Cohen Kappa: \",cohen_kappa)\n",
    "accuracy = accuracy_score(orig_score,pred_score)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### CNN_LSTM Results : MAX Score of all Sentences ###\n",
      "RMSE:  2.656720988335306\n",
      "Cohen Kappa:  0.2583493844094005\n",
      "Accuracy:  0.3474576271186441\n",
      "### CNN_LSTM Results : Min Score of all Sentences ###\n",
      "RMSE:  2.6370011449600854\n",
      "Cohen Kappa:  0.24143335205972272\n",
      "Accuracy:  0.3332049306625578\n",
      "### CNN_LSTM Results : Mean Score of all Sentences ###\n",
      "RMSE:  1.9841436152603542\n",
      "Cohen Kappa:  0.3371955856765654\n",
      "Accuracy:  0.42180277349768874\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.407435</td>\n",
       "      <td>0.043304</td>\n",
       "      <td>0.262295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.763471</td>\n",
       "      <td>0.265039</td>\n",
       "      <td>0.566845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.777683</td>\n",
       "      <td>0.100836</td>\n",
       "      <td>0.422156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.612372</td>\n",
       "      <td>0.521764</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.783896</td>\n",
       "      <td>0.245669</td>\n",
       "      <td>0.507246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.727393</td>\n",
       "      <td>0.236521</td>\n",
       "      <td>0.534392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.858851</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.079470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.424330</td>\n",
       "      <td>-0.011183</td>\n",
       "      <td>0.036496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set      RMSE     Kappa  Accuracy\n",
       "0        1.0  1.407435  0.043304  0.262295\n",
       "1        2.0  0.763471  0.265039  0.566845\n",
       "2        3.0  0.777683  0.100836  0.422156\n",
       "3        4.0  0.612372  0.521764  0.666667\n",
       "4        5.0  0.783896  0.245669  0.507246\n",
       "5        6.0  0.727393  0.236521  0.534392\n",
       "6        7.0  3.858851 -0.000656  0.079470\n",
       "7        8.0  5.424330 -0.011183  0.036496"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will combine the sentences back to essay in this section\n",
    "result_df = pd.DataFrame([x_test_sentence_df.essay_id.values,x_test_sentence_df.essay_set.values,\n",
    "                         x_test_sentence_df.sentence.values,cnn_df.Orig_Score.values,\n",
    "                          cnn_df.Denorm_Pred_Score.values]).transpose()\n",
    "result_df.columns = ['essay_id','essay_set','sentence','orig_score','pred_score']\n",
    "cnn_test_df = find_max_min_mean_score(result_df)\n",
    "\n",
    "#Convert the dataframe parameters into integers as they are returned as floats\n",
    "cnn_test_df.essay_id = cnn_test_df.essay_id.astype(int)\n",
    "cnn_test_df.essay_set = cnn_test_df.essay_set.astype(int)\n",
    "cnn_test_df.Orig_Score = cnn_test_df.Orig_Score.astype(int)\n",
    "cnn_test_df.Max_Score = cnn_test_df.Max_Score.astype(int)\n",
    "cnn_test_df.Min_Score = cnn_test_df.Min_Score.astype(int)\n",
    "cnn_test_df.Mean_Score = cnn_test_df.Mean_Score.astype(int)\n",
    "\n",
    "# Extract the scores\n",
    "orig_score = cnn_test_df.Orig_Score.values\n",
    "max_pred_score = cnn_test_df.Max_Score.values\n",
    "min_pred_score = cnn_test_df.Min_Score.values\n",
    "mean_pred_score = cnn_test_df.Mean_Score.values\n",
    "\n",
    "# Compare the metrics if Max score of all sentences are taken\n",
    "rmse_max_cnn = RMSE(orig_score,max_pred_score)\n",
    "cohen_kappa_max_cnn = cohen_kappa_score(orig_score,max_pred_score)\n",
    "accuracy_max_cnn = accuracy_score(orig_score,max_pred_score)\n",
    "\n",
    "# Compare the metrics if Min score of all sentences are taken\n",
    "rmse_min_cnn = RMSE(orig_score,min_pred_score)\n",
    "cohen_kappa_min_cnn = cohen_kappa_score(orig_score,min_pred_score)\n",
    "accuracy_min_cnn = accuracy_score(orig_score,min_pred_score)\n",
    "\n",
    "# Compare the metrics if Rounded Mean score of all sentences are taken\n",
    "rmse_mean_cnn = RMSE(orig_score,mean_pred_score)\n",
    "cohen_kappa_mean_cnn = cohen_kappa_score(orig_score,mean_pred_score)\n",
    "accuracy_mean_cnn = accuracy_score(orig_score,mean_pred_score)\n",
    "\n",
    "print(\"### CNN_LSTM Results : MAX Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_max_cnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_max_cnn)\n",
    "print(\"Accuracy: \",accuracy_max_cnn)\n",
    "\n",
    "print(\"### CNN_LSTM Results : Min Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_min_cnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_min_cnn)\n",
    "print(\"Accuracy: \",accuracy_min_cnn)\n",
    "\n",
    "print(\"### CNN_LSTM Results : Mean Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_mean_cnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_mean_cnn)\n",
    "print(\"Accuracy: \",accuracy_mean_cnn)\n",
    "\n",
    "# Provide per-essay-set metrics based on mean score\n",
    "essay_set_results = essay_set_metrics(cnn_test_df)\n",
    "essay_set_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "147123/147123 [==============================] - 317s 2ms/step - loss: 0.0486 - acc: 0.0937\n",
      "Epoch 2/20\n",
      "147123/147123 [==============================] - 312s 2ms/step - loss: 0.0305 - acc: 0.0987\n",
      "Epoch 3/20\n",
      "147123/147123 [==============================] - 313s 2ms/step - loss: 0.0279 - acc: 0.0992\n",
      "Epoch 4/20\n",
      "147123/147123 [==============================] - 312s 2ms/step - loss: 0.0269 - acc: 0.1002\n",
      "Epoch 5/20\n",
      "147123/147123 [==============================] - 314s 2ms/step - loss: 0.0264 - acc: 0.1005\n",
      "Epoch 6/20\n",
      "147123/147123 [==============================] - 312s 2ms/step - loss: 0.0261 - acc: 0.1007\n",
      "Epoch 7/20\n",
      "147123/147123 [==============================] - 315s 2ms/step - loss: 0.0259 - acc: 0.1009\n",
      "Epoch 8/20\n",
      "147123/147123 [==============================] - 313s 2ms/step - loss: 0.0256 - acc: 0.1011\n",
      "Epoch 9/20\n",
      "147123/147123 [==============================] - 313s 2ms/step - loss: 0.0253 - acc: 0.1014\n",
      "Epoch 10/20\n",
      "147123/147123 [==============================] - 314s 2ms/step - loss: 0.0251 - acc: 0.1016\n",
      "Epoch 11/20\n",
      "147123/147123 [==============================] - 313s 2ms/step - loss: 0.0249 - acc: 0.1017\n",
      "Epoch 12/20\n",
      "147123/147123 [==============================] - 312s 2ms/step - loss: 0.0246 - acc: 0.1018\n",
      "Epoch 13/20\n",
      "147123/147123 [==============================] - 313s 2ms/step - loss: 0.0243 - acc: 0.1020\n",
      "Epoch 14/20\n",
      "147123/147123 [==============================] - 310s 2ms/step - loss: 0.0242 - acc: 0.1021\n",
      "Epoch 15/20\n",
      "147123/147123 [==============================] - 309s 2ms/step - loss: 0.0240 - acc: 0.1023\n",
      "Epoch 16/20\n",
      "147123/147123 [==============================] - 310s 2ms/step - loss: 0.0238 - acc: 0.1024\n",
      "Epoch 17/20\n",
      "147123/147123 [==============================] - 312s 2ms/step - loss: 0.0236 - acc: 0.1025\n",
      "Epoch 18/20\n",
      "147123/147123 [==============================] - 311s 2ms/step - loss: 0.0233 - acc: 0.1027\n",
      "Epoch 19/20\n",
      "147123/147123 [==============================] - 313s 2ms/step - loss: 0.0232 - acc: 0.1027\n",
      "Epoch 20/20\n",
      "147123/147123 [==============================] - 313s 2ms/step - loss: 0.0230 - acc: 0.1029\n",
      "RMSE:  0.16095059520616758\n",
      "RMSE Sentence Level:  2.6332455776114845\n",
      "Kappa Sentence Level:  0.27302909771760997\n",
      "Accuracy Sentence Level:  0.3353363423785959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:23: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "estimator_lstm = KerasRegressor(build_fn=stack_lstm, epochs=20, batch_size=500)\n",
    "estimator_lstm.fit(train_data, y_train)\n",
    "\n",
    "# Predict for test data\n",
    "prediction_lstm=estimator_lstm.predict(test_data)\n",
    "rmse_val = RMSE(y_test,prediction_lstm)\n",
    "# Find the overall RMSE value. This is not very relevant considering different scale for each set.\n",
    "print(\"RMSE: \",rmse_val)\n",
    "\n",
    "# Construct pandas data frame of scores of each sentences\n",
    "lstm_df = pd.DataFrame([x_test_sentence_df['domain1_score'].astype(np.double), y_test.astype(np.double),\n",
    "                      prediction_lstm.astype(np.double)]).transpose()\n",
    "lstm_df.columns = ['Orig_Score','Norm_Score','Pred_Score']\n",
    "# Find Multiplication factor using the function we defined before\n",
    "lstm_df['Mult_Factor'] = lstm_df.apply(find_mult_factor,axis=1)\n",
    "# Find the denormalized predicted score\n",
    "lstm_df['Denorm_Pred_Score'] = lstm_df.apply(denormalize,axis=1)\n",
    "\n",
    "# Extract the scores of each sentences\n",
    "orig_score = lstm_df.Orig_Score.as_matrix(columns=None)\n",
    "orig_score = orig_score.astype(np.int)\n",
    "pred_score = lstm_df.Denorm_Pred_Score.as_matrix(columns=None)\n",
    "pred_score = pred_score.astype(np.int)\n",
    "\n",
    "# Provide the metrics at sentence level\n",
    "rmse_lstm = RMSE(orig_score,pred_score)\n",
    "cohen_kappa = cohen_kappa_score(orig_score,pred_score)\n",
    "accuracy = accuracy_score(orig_score,pred_score)\n",
    "print(\"RMSE Sentence Level: \",rmse_lstm)\n",
    "print(\"Kappa Sentence Level: \",cohen_kappa)\n",
    "print(\"Accuracy Sentence Level: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Stacked LSTM Results : MAX Score of all Sentences ###\n",
      "RMSE:  2.4402726615191552\n",
      "Cohen Kappa:  0.26221593989910885\n",
      "Accuracy:  0.3559322033898305\n",
      "### Stacked LSTM Results : Min Score of all Sentences ###\n",
      "RMSE:  2.5439889573463472\n",
      "Cohen Kappa:  0.2768123741807381\n",
      "Accuracy:  0.37211093990755006\n",
      "### Stacked LSTM Results : Mean Score of all Sentences ###\n",
      "RMSE:  1.9800624104963735\n",
      "Cohen Kappa:  0.32899367937320956\n",
      "Accuracy:  0.4179506933744222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.384931</td>\n",
       "      <td>0.043037</td>\n",
       "      <td>0.281421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.738549</td>\n",
       "      <td>0.283577</td>\n",
       "      <td>0.580214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.767998</td>\n",
       "      <td>0.078550</td>\n",
       "      <td>0.410180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.598609</td>\n",
       "      <td>0.494258</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.825324</td>\n",
       "      <td>0.182558</td>\n",
       "      <td>0.457971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.723747</td>\n",
       "      <td>0.211094</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.926898</td>\n",
       "      <td>0.018414</td>\n",
       "      <td>0.099338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.305279</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.058394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set      RMSE     Kappa  Accuracy\n",
       "0        1.0  1.384931  0.043037  0.281421\n",
       "1        2.0  0.738549  0.283577  0.580214\n",
       "2        3.0  0.767998  0.078550  0.410180\n",
       "3        4.0  0.598609  0.494258  0.650000\n",
       "4        5.0  0.825324  0.182558  0.457971\n",
       "5        6.0  0.723747  0.211094  0.523810\n",
       "6        7.0  3.926898  0.018414  0.099338\n",
       "7        8.0  5.305279  0.007525  0.058394"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will combine the sentences back to essay in this section\n",
    "\n",
    "result_df = pd.DataFrame([x_test_sentence_df.essay_id.values,x_test_sentence_df.essay_set.values,\n",
    "                         x_test_sentence_df.sentence.values,lstm_df.Orig_Score.values,\n",
    "                          lstm_df.Denorm_Pred_Score.values]).transpose()\n",
    "result_df.columns = ['essay_id','essay_set','sentence','orig_score','pred_score']\n",
    "lstm_test_df = find_max_min_mean_score(result_df)\n",
    "\n",
    "#Convert the dataframe parameters into integers as they are returned as floats\n",
    "lstm_test_df.essay_id = lstm_test_df.essay_id.astype(int)\n",
    "lstm_test_df.essay_set = lstm_test_df.essay_set.astype(int)\n",
    "lstm_test_df.Orig_Score = lstm_test_df.Orig_Score.astype(int)\n",
    "lstm_test_df.Max_Score = lstm_test_df.Max_Score.astype(int)\n",
    "lstm_test_df.Min_Score = lstm_test_df.Min_Score.astype(int)\n",
    "lstm_test_df.Mean_Score = lstm_test_df.Mean_Score.astype(int)\n",
    "\n",
    "# Extract the scores\n",
    "orig_score = lstm_test_df.Orig_Score.values\n",
    "max_pred_score = lstm_test_df.Max_Score.values\n",
    "min_pred_score = lstm_test_df.Min_Score.values\n",
    "mean_pred_score = lstm_test_df.Mean_Score.values\n",
    "\n",
    "# Compare the metrics if Max score of all sentences are taken\n",
    "rmse_max_lstm = RMSE(orig_score,max_pred_score)\n",
    "cohen_kappa_max_lstm = cohen_kappa_score(orig_score,max_pred_score)\n",
    "accuracy_max_lstm = accuracy_score(orig_score,max_pred_score)\n",
    "\n",
    "# Compare the metrics if Min score of all sentences are taken\n",
    "rmse_min_lstm = RMSE(orig_score,min_pred_score)\n",
    "cohen_kappa_min_lstm = cohen_kappa_score(orig_score,min_pred_score)\n",
    "accuracy_min_lstm = accuracy_score(orig_score,min_pred_score)\n",
    "\n",
    "# Compare the metrics if Mean score of all sentences are taken\n",
    "rmse_mean_lstm = RMSE(orig_score,mean_pred_score)\n",
    "cohen_kappa_mean_lstm = cohen_kappa_score(orig_score,mean_pred_score)\n",
    "accuracy_mean_lstm = accuracy_score(orig_score,mean_pred_score)\n",
    "\n",
    "print(\"### Stacked LSTM Results : MAX Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_max_lstm)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_max_lstm)\n",
    "print(\"Accuracy: \",accuracy_max_lstm)\n",
    "\n",
    "print(\"### Stacked LSTM Results : Min Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_min_lstm)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_min_lstm)\n",
    "print(\"Accuracy: \",accuracy_min_lstm)\n",
    "\n",
    "print(\"### Stacked LSTM Results : Mean Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_mean_lstm)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_mean_lstm)\n",
    "print(\"Accuracy: \",accuracy_mean_lstm)\n",
    "\n",
    "# Provide per-essay-set metrics based on mean score\n",
    "essay_set_results = essay_set_metrics(lstm_test_df)\n",
    "essay_set_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "147123/147123 [==============================] - 88s 599us/step - loss: 0.0714 - acc: 0.0879\n",
      "Epoch 2/20\n",
      "147123/147123 [==============================] - 88s 596us/step - loss: 0.0357 - acc: 0.0979\n",
      "Epoch 3/20\n",
      "147123/147123 [==============================] - 87s 589us/step - loss: 0.0311 - acc: 0.0993\n",
      "Epoch 4/20\n",
      "147123/147123 [==============================] - 87s 588us/step - loss: 0.0293 - acc: 0.1000\n",
      "Epoch 5/20\n",
      "147123/147123 [==============================] - 86s 584us/step - loss: 0.0283 - acc: 0.1004\n",
      "Epoch 6/20\n",
      "147123/147123 [==============================] - 86s 584us/step - loss: 0.0276 - acc: 0.1005\n",
      "Epoch 7/20\n",
      "147123/147123 [==============================] - 86s 585us/step - loss: 0.0271 - acc: 0.1008\n",
      "Epoch 8/20\n",
      "147123/147123 [==============================] - 86s 588us/step - loss: 0.0268 - acc: 0.1009\n",
      "Epoch 9/20\n",
      "147123/147123 [==============================] - 87s 588us/step - loss: 0.0263 - acc: 0.1012\n",
      "Epoch 10/20\n",
      "147123/147123 [==============================] - 87s 591us/step - loss: 0.0260 - acc: 0.1012\n",
      "Epoch 11/20\n",
      "147123/147123 [==============================] - 87s 588us/step - loss: 0.0257 - acc: 0.1014\n",
      "Epoch 12/20\n",
      "147123/147123 [==============================] - 86s 582us/step - loss: 0.0255 - acc: 0.1014\n",
      "Epoch 13/20\n",
      "147123/147123 [==============================] - 85s 580us/step - loss: 0.0253 - acc: 0.1015\n",
      "Epoch 14/20\n",
      "147123/147123 [==============================] - 86s 583us/step - loss: 0.0250 - acc: 0.1016\n",
      "Epoch 15/20\n",
      "147123/147123 [==============================] - 85s 579us/step - loss: 0.0248 - acc: 0.1015\n",
      "Epoch 16/20\n",
      "147123/147123 [==============================] - 85s 575us/step - loss: 0.0247 - acc: 0.1019\n",
      "Epoch 17/20\n",
      "147123/147123 [==============================] - 86s 585us/step - loss: 0.0244 - acc: 0.1018\n",
      "Epoch 18/20\n",
      "147123/147123 [==============================] - 86s 585us/step - loss: 0.0243 - acc: 0.1020\n",
      "Epoch 19/20\n",
      "147123/147123 [==============================] - 86s 588us/step - loss: 0.0241 - acc: 0.1021\n",
      "Epoch 20/20\n",
      "147123/147123 [==============================] - 87s 590us/step - loss: 0.0240 - acc: 0.1021\n",
      "RMSE:  0.1607020235310356\n",
      "RMSE Sentence Level:  2.6639661085872213\n",
      "Kappa Sentence Level:  0.27161626944889117\n",
      "Accuracy Sentence Level:  0.3330795584316711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:23: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "estimator = KerasRegressor(build_fn=GRU, epochs=20, batch_size=500)\n",
    "estimator.fit(train_data, y_train)\n",
    "\n",
    "# Predict for test data\n",
    "prediction_rnn=estimator.predict(test_data)\n",
    "rmse_val = RMSE(y_test,prediction_rnn)\n",
    "# Find the overall RMSE value. This is not very relevant considering different scale for each set.\n",
    "print(\"RMSE: \",rmse_val)\n",
    "\n",
    "# Construct pandas data frame of scores of each sentences\n",
    "rnn_df = pd.DataFrame([x_test_sentence_df['domain1_score'].astype(np.double), y_test.astype(np.double),\n",
    "                      prediction_rnn.astype(np.double)]).transpose()\n",
    "rnn_df.columns = ['Orig_Score','Norm_Score','Pred_Score']\n",
    "# Find Multiplication factor using the function we defined before\n",
    "rnn_df['Mult_Factor'] = rnn_df.apply(find_mult_factor,axis=1)\n",
    "# Find the denormalized predicted score\n",
    "rnn_df['Denorm_Pred_Score'] = rnn_df.apply(denormalize,axis=1)\n",
    "\n",
    "# Extract the scores of each sentences\n",
    "orig_score = rnn_df.Orig_Score.as_matrix(columns=None)\n",
    "orig_score = orig_score.astype(np.int)\n",
    "pred_score = rnn_df.Denorm_Pred_Score.as_matrix(columns=None)\n",
    "pred_score = pred_score.astype(np.int)\n",
    "\n",
    "# Provide the metrics at sentence level\n",
    "rmse_rnn = RMSE(orig_score,pred_score)\n",
    "cohen_kappa = cohen_kappa_score(orig_score,pred_score)\n",
    "accuracy = accuracy_score(orig_score,pred_score)\n",
    "print(\"RMSE Sentence Level: \",rmse_rnn)\n",
    "print(\"Kappa Sentence Level: \",cohen_kappa)\n",
    "print(\"Accuracy Sentence Level: \",accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### RNN GRU Results : MAX Score of all Sentences ###\n",
      "RMSE:  2.47802359240166\n",
      "Cohen Kappa:  0.24640110969689533\n",
      "Accuracy:  0.33782742681047767\n",
      "### RNN GRU Results : Min Score of all Sentences ###\n",
      "RMSE:  2.48988709591122\n",
      "Cohen Kappa:  0.2994161154737035\n",
      "Accuracy:  0.3940677966101695\n",
      "### RNN GRU Results : Mean Score of all Sentences ###\n",
      "RMSE:  1.966299270132258\n",
      "Cohen Kappa:  0.3049514854524614\n",
      "Accuracy:  0.3956086286594761\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.426716</td>\n",
       "      <td>0.028712</td>\n",
       "      <td>0.229508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.775632</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.548128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.777683</td>\n",
       "      <td>0.056194</td>\n",
       "      <td>0.395210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.598609</td>\n",
       "      <td>0.483702</td>\n",
       "      <td>0.641667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.827078</td>\n",
       "      <td>0.153610</td>\n",
       "      <td>0.437681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.768080</td>\n",
       "      <td>0.164754</td>\n",
       "      <td>0.505291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.863996</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.086093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.244392</td>\n",
       "      <td>-0.002928</td>\n",
       "      <td>0.051095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set      RMSE     Kappa  Accuracy\n",
       "0        1.0  1.426716  0.028712  0.229508\n",
       "1        2.0  0.775632  0.237609  0.548128\n",
       "2        3.0  0.777683  0.056194  0.395210\n",
       "3        4.0  0.598609  0.483702  0.641667\n",
       "4        5.0  0.827078  0.153610  0.437681\n",
       "5        6.0  0.768080  0.164754  0.505291\n",
       "6        7.0  3.863996  0.000635  0.086093\n",
       "7        8.0  5.244392 -0.002928  0.051095"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will combine the sentences back to essay in this section\n",
    "\n",
    "result_df = pd.DataFrame([x_test_sentence_df.essay_id.values,x_test_sentence_df.essay_set.values,\n",
    "                         x_test_sentence_df.sentence.values,rnn_df.Orig_Score.values,\n",
    "                          rnn_df.Denorm_Pred_Score.values]).transpose()\n",
    "result_df.columns = ['essay_id','essay_set','sentence','orig_score','pred_score']\n",
    "rnn_test_df = find_max_min_mean_score(result_df)\n",
    "\n",
    "#Convert the dataframe parameters into integers as they are returned as floats\n",
    "rnn_test_df.essay_id = rnn_test_df.essay_id.astype(int)\n",
    "rnn_test_df.essay_set = rnn_test_df.essay_set.astype(int)\n",
    "rnn_test_df.Orig_Score = rnn_test_df.Orig_Score.astype(int)\n",
    "rnn_test_df.Max_Score = rnn_test_df.Max_Score.astype(int)\n",
    "rnn_test_df.Min_Score = rnn_test_df.Min_Score.astype(int)\n",
    "rnn_test_df.Mean_Score = rnn_test_df.Mean_Score.astype(int)\n",
    "\n",
    "# Extract the scores\n",
    "orig_score = rnn_test_df.Orig_Score.values\n",
    "max_pred_score = rnn_test_df.Max_Score.values\n",
    "min_pred_score = rnn_test_df.Min_Score.values\n",
    "mean_pred_score = rnn_test_df.Mean_Score.values\n",
    "\n",
    "# Compare the metrics if Max score of all sentences are taken\n",
    "rmse_max_rnn = RMSE(orig_score,max_pred_score)\n",
    "cohen_kappa_max_rnn = cohen_kappa_score(orig_score,max_pred_score)\n",
    "accuracy_max_rnn = accuracy_score(orig_score,max_pred_score)\n",
    "\n",
    "# Compare the metrics if Min score of all sentences are taken\n",
    "rmse_min_rnn = RMSE(orig_score,min_pred_score)\n",
    "cohen_kappa_min_rnn = cohen_kappa_score(orig_score,min_pred_score)\n",
    "accuracy_min_rnn = accuracy_score(orig_score,min_pred_score)\n",
    "\n",
    "# Compare the metrics if Mean score of all sentences are taken\n",
    "rmse_mean_rnn = RMSE(orig_score,mean_pred_score)\n",
    "cohen_kappa_mean_rnn = cohen_kappa_score(orig_score,mean_pred_score)\n",
    "accuracy_mean_rnn = accuracy_score(orig_score,mean_pred_score)\n",
    "\n",
    "print(\"### RNN GRU Results : MAX Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_max_rnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_max_rnn)\n",
    "print(\"Accuracy: \",accuracy_max_rnn)\n",
    "\n",
    "print(\"### RNN GRU Results : Min Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_min_rnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_min_rnn)\n",
    "print(\"Accuracy: \",accuracy_min_rnn)\n",
    "\n",
    "print(\"### RNN GRU Results : Mean Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_mean_rnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_mean_rnn)\n",
    "print(\"Accuracy: \",accuracy_mean_rnn)\n",
    "\n",
    "# Provide per-essay-set metrics based on mean score\n",
    "essay_set_results = essay_set_metrics(rnn_test_df)\n",
    "essay_set_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed Forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "147123/147123 [==============================] - 3s 18us/step - loss: 0.0451 - acc: 0.0983\n",
      "Epoch 2/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0291 - acc: 0.0990\n",
      "Epoch 3/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0278 - acc: 0.0994\n",
      "Epoch 4/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0268 - acc: 0.1001\n",
      "Epoch 5/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0259 - acc: 0.1005\n",
      "Epoch 6/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0251 - acc: 0.1011\n",
      "Epoch 7/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0242 - acc: 0.1015\n",
      "Epoch 8/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0234 - acc: 0.1020\n",
      "Epoch 9/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0224 - acc: 0.1025\n",
      "Epoch 10/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0216 - acc: 0.1029\n",
      "Epoch 11/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0208 - acc: 0.1031\n",
      "Epoch 12/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0201 - acc: 0.1034\n",
      "Epoch 13/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0193 - acc: 0.1037\n",
      "Epoch 14/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0186 - acc: 0.1038\n",
      "Epoch 15/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0179 - acc: 0.1041\n",
      "Epoch 16/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0175 - acc: 0.1040\n",
      "Epoch 17/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0169 - acc: 0.1042\n",
      "Epoch 18/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0165 - acc: 0.1044\n",
      "Epoch 19/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0160 - acc: 0.1044\n",
      "Epoch 20/20\n",
      "147123/147123 [==============================] - 1s 7us/step - loss: 0.0157 - acc: 0.1044\n",
      "RMSE:  0.176930690770953\n",
      "RMSE Sentence Level:  2.9798752182391857\n",
      "Kappa Sentence Level:  0.24495590024904945\n",
      "Accuracy Sentence Level:  0.308554026863886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:23: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "estimator_nn = KerasRegressor(build_fn=FF_NN, epochs=20, batch_size=500)\n",
    "estimator_nn.fit(train_data, y_train)\n",
    "\n",
    "# Predict for test data\n",
    "prediction_nn=estimator_nn.predict(test_data)\n",
    "rmse_val = RMSE(y_test,prediction_nn)\n",
    "# Find the overall RMSE value. This is not very relevant considering different scale for each set.\n",
    "print(\"RMSE: \",rmse_val)\n",
    "\n",
    "# Construct pandas data frame of scores of each sentences\n",
    "nn_df = pd.DataFrame([x_test_sentence_df['domain1_score'].astype(np.double), y_test.astype(np.double),\n",
    "                      prediction_nn.astype(np.double)]).transpose()\n",
    "nn_df.columns = ['Orig_Score','Norm_Score','Pred_Score']\n",
    "# Find Multiplication factor using the function we defined before\n",
    "nn_df['Mult_Factor'] = nn_df.apply(find_mult_factor,axis=1)\n",
    "# Find the denormalized predicted score\n",
    "nn_df['Denorm_Pred_Score'] = nn_df.apply(denormalize,axis=1)\n",
    "\n",
    "# Extract the scores of each sentences\n",
    "orig_score = nn_df.Orig_Score.as_matrix(columns=None)\n",
    "orig_score = orig_score.astype(np.int)\n",
    "pred_score = nn_df.Denorm_Pred_Score.as_matrix(columns=None)\n",
    "pred_score = pred_score.astype(np.int)\n",
    "\n",
    "# Provide the metrics at sentence level\n",
    "rmse_nn = RMSE(orig_score,pred_score)\n",
    "cohen_kappa = cohen_kappa_score(orig_score,pred_score)\n",
    "accuracy = accuracy_score(orig_score,pred_score)\n",
    "print(\"RMSE Sentence Level: \",rmse_nn)\n",
    "print(\"Kappa Sentence Level: \",cohen_kappa)\n",
    "print(\"Accuracy Sentence Level: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Simple FF NN Results : MAX Score of all Sentences ###\n",
      "RMSE:  3.132721585147047\n",
      "Cohen Kappa:  0.1953363332195014\n",
      "Accuracy:  0.288135593220339\n",
      "### Simple FF NN Results : Min Score of all Sentences ###\n",
      "RMSE:  3.3338854190978644\n",
      "Cohen Kappa:  0.21383702599770982\n",
      "Accuracy:  0.31587057010785824\n",
      "### Simple FF NN Results : Mean Score of all Sentences ###\n",
      "RMSE:  2.071153404571869\n",
      "Cohen Kappa:  0.2887425982170171\n",
      "Accuracy:  0.3817411402157165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.442902</td>\n",
       "      <td>0.035802</td>\n",
       "      <td>0.240437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.802736</td>\n",
       "      <td>0.203135</td>\n",
       "      <td>0.526738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.789148</td>\n",
       "      <td>0.056629</td>\n",
       "      <td>0.395210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.654047</td>\n",
       "      <td>0.383315</td>\n",
       "      <td>0.572222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.879723</td>\n",
       "      <td>0.138566</td>\n",
       "      <td>0.426087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.835711</td>\n",
       "      <td>0.141745</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.221515</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>0.082781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.306655</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.051095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set      RMSE     Kappa  Accuracy\n",
       "0        1.0  1.442902  0.035802  0.240437\n",
       "1        2.0  0.802736  0.203135  0.526738\n",
       "2        3.0  0.789148  0.056629  0.395210\n",
       "3        4.0  0.654047  0.383315  0.572222\n",
       "4        5.0  0.879723  0.138566  0.426087\n",
       "5        6.0  0.835711  0.141745  0.500000\n",
       "6        7.0  4.221515  0.004166  0.082781\n",
       "7        8.0  5.306655  0.003413  0.051095"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will combine the sentences back to essay in this section\n",
    "\n",
    "result_df = pd.DataFrame([x_test_sentence_df.essay_id.values,x_test_sentence_df.essay_set.values,\n",
    "                         x_test_sentence_df.sentence.values,nn_df.Orig_Score.values,\n",
    "                          nn_df.Denorm_Pred_Score.values]).transpose()\n",
    "result_df.columns = ['essay_id','essay_set','sentence','orig_score','pred_score']\n",
    "nn_test_df = find_max_min_mean_score(result_df)\n",
    "\n",
    "#Convert the dataframe parameters into integers as they are returned as floats\n",
    "nn_test_df.essay_id = nn_test_df.essay_id.astype(int)\n",
    "nn_test_df.essay_set = nn_test_df.essay_set.astype(int)\n",
    "nn_test_df.Orig_Score = nn_test_df.Orig_Score.astype(int)\n",
    "nn_test_df.Max_Score = nn_test_df.Max_Score.astype(int)\n",
    "nn_test_df.Min_Score = nn_test_df.Min_Score.astype(int)\n",
    "nn_test_df.Mean_Score = nn_test_df.Mean_Score.astype(int)\n",
    "\n",
    "# Extract the scores\n",
    "orig_score = nn_test_df.Orig_Score.values\n",
    "max_pred_score = nn_test_df.Max_Score.values\n",
    "min_pred_score = nn_test_df.Min_Score.values\n",
    "mean_pred_score = nn_test_df.Mean_Score.values\n",
    "\n",
    "# Compare the metrics if Max score of all sentences are taken\n",
    "rmse_max_nn = RMSE(orig_score,max_pred_score)\n",
    "cohen_kappa_max_nn = cohen_kappa_score(orig_score,max_pred_score)\n",
    "accuracy_max_nn = accuracy_score(orig_score,max_pred_score)\n",
    "\n",
    "# Compare the metrics if Min score of all sentences are taken\n",
    "rmse_min_nn = RMSE(orig_score,min_pred_score)\n",
    "cohen_kappa_min_nn = cohen_kappa_score(orig_score,min_pred_score)\n",
    "accuracy_min_nn = accuracy_score(orig_score,min_pred_score)\n",
    "\n",
    "# Compare the metrics if Mean score of all sentences are taken\n",
    "rmse_mean_nn = RMSE(orig_score,mean_pred_score)\n",
    "cohen_kappa_mean_nn = cohen_kappa_score(orig_score,mean_pred_score)\n",
    "accuracy_mean_nn = accuracy_score(orig_score,mean_pred_score)\n",
    "\n",
    "print(\"### Simple FF NN Results : MAX Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_max_nn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_max_nn)\n",
    "print(\"Accuracy: \",accuracy_max_nn)\n",
    "\n",
    "print(\"### Simple FF NN Results : Min Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_min_nn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_min_nn)\n",
    "print(\"Accuracy: \",accuracy_min_nn)\n",
    "\n",
    "print(\"### Simple FF NN Results : Mean Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_mean_nn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_mean_nn)\n",
    "print(\"Accuracy: \",accuracy_mean_nn)\n",
    "\n",
    "# Provide per-essay-set metrics based on mean score\n",
    "essay_set_results = essay_set_metrics(nn_test_df)\n",
    "essay_set_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
