{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import json, os, re, shutil, sys, time\n",
    "import seaborn as sns\n",
    "from importlib import reload\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "from collections import defaultdict\n",
    "import xmltodict\n",
    "import untangle\n",
    "import xml.etree.ElementTree as ET\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Import spacy\n",
    "import spacy\n",
    "\n",
    "# NumPy, Pandas and TensorFlow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import CONTRACTION_MAP\n",
    "import unicodedata\n",
    "\n",
    "from numpy.random import seed\n",
    "from pandas import read_csv, DataFrame\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "## Plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score      ...        \\\n",
       "0             NaN             NaN            NaN      ...         \n",
       "1             NaN             NaN            NaN      ...         \n",
       "2             NaN             NaN            NaN      ...         \n",
       "3             NaN             NaN            NaN      ...         \n",
       "4             NaN             NaN            NaN      ...         \n",
       "\n",
       "   rater2_trait3  rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aeg_long = pd.read_csv(\"../data-DNC/AEG/training_set_rel3.tsv\",sep='\\t',encoding = \"latin1\")\n",
    "#aeg_long.columns = aeg_long.iloc[0]\n",
    "#aeg_long.reindex(aeg_long.index.drop(0))\n",
    "aeg_long.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = ET.parse('../data-DNC/AESW/aesw2016_v1.2_train.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_attrib = list()\n",
    "sent_text = list()\n",
    "for sent in root.iter('sentence'):\n",
    "    sent_attrib.append(sent.attrib['sid'])\n",
    "    sent_text.append(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_dict = dict()\n",
    "for sent in root.iter('sentence'):\n",
    "    sid = sent.attrib['sid']\n",
    "    sent_dict[sid]=sent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189412"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AESW Data for grammatical errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>To facilitate an easier notation throughout t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>To facilitate an easier notation throughout t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Therefore MATH defines a special order of tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>This is important since only MATH is the real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Note that in all contour time-integrals we es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1                                                  2\n",
       "0  1  1.0   To facilitate an easier notation throughout t...\n",
       "1 -1  1.0   To facilitate an easier notation throughout t...\n",
       "2  0  1.1   Therefore MATH defines a special order of tim...\n",
       "3  0  1.2   This is important since only MATH is the real...\n",
       "4  0  1.3   Note that in all contour time-integrals we es..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aesw_train_labels = pd.read_csv(\"../data-DNC/AESW/aesw2016_v1.2_train.tok\",sep='\\t',encoding = \"latin1\",header=None)\n",
    "aesw_train_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1196941"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aesw_train_labels.columns = ['Key_ID','Sent_ID','Text']\n",
    "aesw_train_labels = aesw_train_labels[aesw_train_labels.Key_ID!=-1]\n",
    "len(aesw_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>To facilitate an easier notation throughout t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Therefore MATH defines a special order of tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>This is important since only MATH is the real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Note that in all contour time-integrals we es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Theorem REF proves the equivalence of ensembl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Key_ID  Sent_ID                                               Text\n",
       "0       1      1.0   To facilitate an easier notation throughout t...\n",
       "2       0      1.1   Therefore MATH defines a special order of tim...\n",
       "3       0      1.2   This is important since only MATH is the real...\n",
       "4       0      1.3   Note that in all contour time-integrals we es...\n",
       "5       0      2.0   Theorem REF proves the equivalence of ensembl..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aesw_train_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = aesw_train_labels.Text\n",
    "y_train = aesw_train_labels.Key_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The team of robots in Chapter REF and CITE cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>The Hamiltonian -LRB- Lyapunov function -RRB-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>The Hamiltonian -LRB- Lyapunov function -RRB-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Therefore , for MATH robots , the time deriva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Therefore , for MATH robots the time derivati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1                                                  2\n",
       "0  0  1.0   The team of robots in Chapter REF and CITE cr...\n",
       "1  1  1.1   The Hamiltonian -LRB- Lyapunov function -RRB-...\n",
       "2 -1  1.1   The Hamiltonian -LRB- Lyapunov function -RRB-...\n",
       "3  1  1.2   Therefore , for MATH robots , the time deriva...\n",
       "4 -1  1.2   Therefore , for MATH robots the time derivati..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aesw_dev_labels = pd.read_csv(\"../data-DNC/AESW/aesw2016_v1.2_dev.tok\",sep='\\t',encoding = \"latin1\",header=None)\n",
    "aesw_dev_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148478"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aesw_dev_labels.columns = ['Key_ID','Sent_ID','Text']\n",
    "aesw_dev_labels = aesw_dev_labels[aesw_dev_labels.Key_ID!=-1]\n",
    "len(aesw_dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_dev = aesw_dev_labels.Text\n",
    "y_dev = aesw_dev_labels.Key_ID.as_matrix(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "data = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1196941, 50)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148478, 50)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_seq = tokenizer.texts_to_sequences(x_dev)\n",
    "dev_data = pad_sequences(dev_seq, maxlen=50)\n",
    "dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e3a4ed753abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed(2017)\n",
    "conv = Sequential()\n",
    "conv.add(Embedding(vocabulary_size, 100, input_length=50))\n",
    "conv.add(Conv1D(64, 5, activation = 'relu'))\n",
    "conv.add(MaxPooling1D(2))\n",
    "conv.add(Flatten())\n",
    "conv.add(Dense(1, activation = 'sigmoid'))\n",
    "sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "conv.compile(loss = 'binary_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "conv.fit(data, y_train, batch_size = 500, epochs = 40, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6545212085292097\n"
     ]
    }
   ],
   "source": [
    "pred = conv.predict(dev_data)\n",
    "pred_labels = (pred > 0.5).astype(np.int)\n",
    "pred_labels = np.reshape(pred_labels,[148478,])\n",
    "\n",
    "#print(y_dev[0:5])\n",
    "#print(pred_labels[0:5])\n",
    "accuracy = accuracy_score(y_dev,pred_labels)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148478,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_dev))\n",
    "print(type(y_dev))\n",
    "print(type(pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ted_main = pd.read_csv(\"../data-DNC/TED/ted_main.csv\")\n",
    "ted_transcript = pd.read_csv(\"../data-DNC/TED/transcripts.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>film_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>num_speaker</th>\n",
       "      <th>published_date</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2.550000e+03</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2.550000e+03</td>\n",
       "      <td>2.550000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>191.562353</td>\n",
       "      <td>826.510196</td>\n",
       "      <td>1.321928e+09</td>\n",
       "      <td>27.326275</td>\n",
       "      <td>1.028235</td>\n",
       "      <td>1.343525e+09</td>\n",
       "      <td>1.698297e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>282.315223</td>\n",
       "      <td>374.009138</td>\n",
       "      <td>1.197391e+08</td>\n",
       "      <td>9.563452</td>\n",
       "      <td>0.207705</td>\n",
       "      <td>9.464009e+07</td>\n",
       "      <td>2.498479e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>7.464960e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.151367e+09</td>\n",
       "      <td>5.044300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>1.257466e+09</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.268463e+09</td>\n",
       "      <td>7.557928e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>118.000000</td>\n",
       "      <td>848.000000</td>\n",
       "      <td>1.333238e+09</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.340935e+09</td>\n",
       "      <td>1.124524e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>221.750000</td>\n",
       "      <td>1046.750000</td>\n",
       "      <td>1.412964e+09</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.423432e+09</td>\n",
       "      <td>1.700760e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6404.000000</td>\n",
       "      <td>5256.000000</td>\n",
       "      <td>1.503792e+09</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.506092e+09</td>\n",
       "      <td>4.722711e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          comments     duration     film_date    languages  num_speaker  \\\n",
       "count  2550.000000  2550.000000  2.550000e+03  2550.000000  2550.000000   \n",
       "mean    191.562353   826.510196  1.321928e+09    27.326275     1.028235   \n",
       "std     282.315223   374.009138  1.197391e+08     9.563452     0.207705   \n",
       "min       2.000000   135.000000  7.464960e+07     0.000000     1.000000   \n",
       "25%      63.000000   577.000000  1.257466e+09    23.000000     1.000000   \n",
       "50%     118.000000   848.000000  1.333238e+09    28.000000     1.000000   \n",
       "75%     221.750000  1046.750000  1.412964e+09    33.000000     1.000000   \n",
       "max    6404.000000  5256.000000  1.503792e+09    72.000000     5.000000   \n",
       "\n",
       "       published_date         views  \n",
       "count    2.550000e+03  2.550000e+03  \n",
       "mean     1.343525e+09  1.698297e+06  \n",
       "std      9.464009e+07  2.498479e+06  \n",
       "min      1.151367e+09  5.044300e+04  \n",
       "25%      1.268463e+09  7.557928e+05  \n",
       "50%      1.340935e+09  1.124524e+06  \n",
       "75%      1.423432e+09  1.700760e+06  \n",
       "max      1.506092e+09  4.722711e+07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_main.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2467</td>\n",
       "      <td>2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2464</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>I'm going to tell you a little bit about my TE...</td>\n",
       "      <td>https://www.ted.com/talks/brene_brown_listenin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               transcript  \\\n",
       "count                                                2467   \n",
       "unique                                               2464   \n",
       "top     I'm going to tell you a little bit about my TE...   \n",
       "freq                                                    2   \n",
       "\n",
       "                                                      url  \n",
       "count                                                2467  \n",
       "unique                                               2464  \n",
       "top     https://www.ted.com/talks/brene_brown_listenin...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_transcript.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>film_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>num_speaker</th>\n",
       "      <th>published_date</th>\n",
       "      <th>ratings</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4553</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 19645}, {...</td>\n",
       "      <td>[{'id': 865, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "      <td>47227110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>265</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>43</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 544}, {'i...</td>\n",
       "      <td>[{'id': 243, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Climate advocate</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
       "      <td>3200520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>1286</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140739200</td>\n",
       "      <td>26</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 964}, {'i...</td>\n",
       "      <td>[{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Technology columnist</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
       "      <td>1636292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>1116</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140912000</td>\n",
       "      <td>35</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 3, 'name': 'Courageous', 'count': 760}...</td>\n",
       "      <td>[{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Activist for environmental justice</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_s_tale...</td>\n",
       "      <td>1697550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>1190</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140566400</td>\n",
       "      <td>48</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>1</td>\n",
       "      <td>1151440680</td>\n",
       "      <td>[{'id': 9, 'name': 'Ingenious', 'count': 3202}...</td>\n",
       "      <td>[{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Global health expert; data visionary</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_shows_t...</td>\n",
       "      <td>12005869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments                                        description  duration  \\\n",
       "0      4553  Sir Ken Robinson makes an entertaining and pro...      1164   \n",
       "1       265  With the same humor and humanity he exuded in ...       977   \n",
       "2       124  New York Times columnist David Pogue takes aim...      1286   \n",
       "3       200  In an emotionally charged talk, MacArthur-winn...      1116   \n",
       "4       593  You've never seen data presented like this. Wi...      1190   \n",
       "\n",
       "     event   film_date  languages   main_speaker  \\\n",
       "0  TED2006  1140825600         60   Ken Robinson   \n",
       "1  TED2006  1140825600         43        Al Gore   \n",
       "2  TED2006  1140739200         26    David Pogue   \n",
       "3  TED2006  1140912000         35  Majora Carter   \n",
       "4  TED2006  1140566400         48   Hans Rosling   \n",
       "\n",
       "                                            name  num_speaker  published_date  \\\n",
       "0      Ken Robinson: Do schools kill creativity?            1      1151367060   \n",
       "1           Al Gore: Averting the climate crisis            1      1151367060   \n",
       "2                  David Pogue: Simplicity sells            1      1151367060   \n",
       "3             Majora Carter: Greening the ghetto            1      1151367060   \n",
       "4  Hans Rosling: The best stats you've ever seen            1      1151440680   \n",
       "\n",
       "                                             ratings  \\\n",
       "0  [{'id': 7, 'name': 'Funny', 'count': 19645}, {...   \n",
       "1  [{'id': 7, 'name': 'Funny', 'count': 544}, {'i...   \n",
       "2  [{'id': 7, 'name': 'Funny', 'count': 964}, {'i...   \n",
       "3  [{'id': 3, 'name': 'Courageous', 'count': 760}...   \n",
       "4  [{'id': 9, 'name': 'Ingenious', 'count': 3202}...   \n",
       "\n",
       "                                       related_talks  \\\n",
       "0  [{'id': 865, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "1  [{'id': 243, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "2  [{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "3  [{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "4  [{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "\n",
       "                     speaker_occupation  \\\n",
       "0                       Author/educator   \n",
       "1                      Climate advocate   \n",
       "2                  Technology columnist   \n",
       "3    Activist for environmental justice   \n",
       "4  Global health expert; data visionary   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['children', 'creativity', 'culture', 'dance',...   \n",
       "1  ['alternative energy', 'cars', 'climate change...   \n",
       "2  ['computers', 'entertainment', 'interface desi...   \n",
       "3  ['MacArthur grant', 'activism', 'business', 'c...   \n",
       "4  ['Africa', 'Asia', 'Google', 'demo', 'economic...   \n",
       "\n",
       "                             title  \\\n",
       "0      Do schools kill creativity?   \n",
       "1      Averting the climate crisis   \n",
       "2                 Simplicity sells   \n",
       "3              Greening the ghetto   \n",
       "4  The best stats you've ever seen   \n",
       "\n",
       "                                                 url     views  \n",
       "0  https://www.ted.com/talks/ken_robinson_says_sc...  47227110  \n",
       "1  https://www.ted.com/talks/al_gore_on_averting_...   3200520  \n",
       "2  https://www.ted.com/talks/david_pogue_says_sim...   1636292  \n",
       "3  https://www.ted.com/talks/majora_carter_s_tale...   1697550  \n",
       "4  https://www.ted.com/talks/hans_rosling_shows_t...  12005869  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_main.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're here today â€” and I'm very happy that...</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_s_tale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>About 10 years ago, I took on the task to teac...</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_shows_t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  Good morning. How are you?(Laughter)It's been ...   \n",
       "1  Thank you so much, Chris. And it's truly a gre...   \n",
       "2  (Music: \"The Sound of Silence,\" Simon & Garfun...   \n",
       "3  If you're here today â€” and I'm very happy that...   \n",
       "4  About 10 years ago, I took on the task to teac...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.ted.com/talks/ken_robinson_says_sc...  \n",
       "1  https://www.ted.com/talks/al_gore_on_averting_...  \n",
       "2  https://www.ted.com/talks/david_pogue_says_sim...  \n",
       "3  https://www.ted.com/talks/majora_carter_s_tale...  \n",
       "4  https://www.ted.com/talks/hans_rosling_shows_t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_transcript.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2550\n",
      "2467\n"
     ]
    }
   ],
   "source": [
    "print(len(ted_main))\n",
    "print(len(ted_transcript))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not all TED MAIN has a transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2464"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_match = ted_main[ted_main.url.isin(ted_transcript.url)]\n",
    "ted_notmatch = ted_main[~ted_main.url.isin(ted_transcript.url)]\n",
    "len(ted_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = aeg_long.essay[0]\n",
    "#sentence = ted_transcript.transcript[0]\n",
    "s0 = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = Text(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear local newspaper , I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people , helps us learn about the globe ( astronomy ) and keeps us out of troble ! Thing about ! Dont you think so ? How would you feel if your teenager is always on the phone with friends ! Do you ever time to chat with your friends or buisness partner about things . Well now - there 's a new way to chat the computer , theirs plenty of sites on the internet to do so : @ ORGANIZATION1 , @ ORGANIZATION2 , @ CAPS1 , facebook , myspace ect . Just think now while your setting up meeting with your boss on the computer , your teenager is having fun on the phone not rushing to get off cause you want to use it . How did you learn about other countrys/states outside of yours ? Well I have by computer/internet , it 's a new way to learn about what going on in our time ! You might think your child spends a lot of time on the computer , but ask them so question about the economy , sea floor spreading or even about the @ DATE1 's you 'll be surprise at how much he/she knows . Believe it or not the computer is much interesting then in class all day reading out of books . If your child is home on your computer or at a local library , it 's better than being out with friends being fresh , or being perpressured to doing something they know isnt right . You might not know where your child is , @ CAPS2 forbidde in a hospital bed because of a drive-by . Rather than your child on the computer learning , chatting or just playing games , safe and sound in your home or community place . Now I hope you have reached a point to understand and agree with me , because computers can have great effects on you or child because it gives us time to chat with friends/new people , helps us learn about the globe and believe or not keeps us out of troble . Thank you for listening .\n"
     ]
    }
   ],
   "source": [
    "sentence_mod = ' '.join(s0)\n",
    "print(sentence_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4689119170984456"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "lexical_diversity(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar(word):\n",
    "    queries = [w for w in word.vocab if w.is_lower == word.is_lower and w.prob >= -15]\n",
    "    by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "    return by_similarity[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#word_syn_list = [wordnet_lemmatizer.lemmatize(w.lower_) for w in most_similar(nlp.vocab[u'Dear'])]\n",
    "word_syn_list = [w.lower_ for w in most_similar(nlp.vocab[u'Safe'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'safe', 'safety', 'secure'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(word_syn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.lexeme.Lexeme'>\n"
     ]
    }
   ],
   "source": [
    "w_sample = nlp.vocab[u'Safe']\n",
    "print(type(w_sample))\n",
    "for w in w_sample.vocab:\n",
    "    print(w.prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(sentence_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spacy_pos_tagged = [(word, word.tag_, word.pos_) for word in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_spacy = pd.DataFrame(spacy_pos_tagged, columns=['Word', 'POS tag', 'Tag type'])\n",
    "nltk_pos_tagged = nltk.pos_tag(sentence.split())\n",
    "df_nltk = pd.DataFrame(nltk_pos_tagged, columns=['Word', 'POS tag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS tag</th>\n",
       "      <th>Tag type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>local</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newspaper</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>think</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>effects</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>computers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>on</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>people</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>great</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>learning</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>skills</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>affects</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>because</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>give</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>us</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>time</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chat</td>\n",
       "      <td>VB</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>with</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>friends</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>new</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>people</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>time</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>chat</td>\n",
       "      <td>VB</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>with</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>friends</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>new</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>people</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>helps</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>us</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>learn</td>\n",
       "      <td>VB</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>about</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>globe</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>believe</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>or</td>\n",
       "      <td>CC</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>not</td>\n",
       "      <td>RB</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>keeps</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>us</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>out</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>troble</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Thank</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>you</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>for</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>listening</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word POS tag Tag type\n",
       "0         Dear      JJ      ADJ\n",
       "1        local      JJ      ADJ\n",
       "2    newspaper      NN     NOUN\n",
       "3            ,       ,    PUNCT\n",
       "4            I     PRP     PRON\n",
       "5        think     VBP     VERB\n",
       "6      effects     NNS     NOUN\n",
       "7    computers     NNS     NOUN\n",
       "8         have     VBP     VERB\n",
       "9           on      IN      ADP\n",
       "10      people     NNS     NOUN\n",
       "11         are     VBP     VERB\n",
       "12       great      JJ      ADJ\n",
       "13    learning      NN     NOUN\n",
       "14      skills     NNS     NOUN\n",
       "15           /     SYM      SYM\n",
       "16     affects     NNS     NOUN\n",
       "17     because      IN      ADP\n",
       "18        they     PRP     PRON\n",
       "19        give     VBP     VERB\n",
       "20          us     PRP     PRON\n",
       "21        time      NN     NOUN\n",
       "22          to      TO     PART\n",
       "23        chat      VB     VERB\n",
       "24        with      IN      ADP\n",
       "25     friends     NNS     NOUN\n",
       "26           /     SYM      SYM\n",
       "27         new      JJ      ADJ\n",
       "28      people     NNS     NOUN\n",
       "29           ,       ,    PUNCT\n",
       "..         ...     ...      ...\n",
       "372       time      NN     NOUN\n",
       "373         to      TO     PART\n",
       "374       chat      VB     VERB\n",
       "375       with      IN      ADP\n",
       "376    friends     NNS     NOUN\n",
       "377          /     SYM      SYM\n",
       "378        new      JJ      ADJ\n",
       "379     people     NNS     NOUN\n",
       "380          ,       ,    PUNCT\n",
       "381      helps     VBZ     VERB\n",
       "382         us     PRP     PRON\n",
       "383      learn      VB     VERB\n",
       "384      about      IN      ADP\n",
       "385        the      DT      DET\n",
       "386      globe      NN     NOUN\n",
       "387        and      CC    CCONJ\n",
       "388    believe     VBP     VERB\n",
       "389         or      CC    CCONJ\n",
       "390        not      RB      ADV\n",
       "391      keeps     VBZ     VERB\n",
       "392         us     PRP     PRON\n",
       "393        out      IN      ADP\n",
       "394         of      IN      ADP\n",
       "395     troble      JJ      ADJ\n",
       "396          .       .    PUNCT\n",
       "397      Thank     VBP     VERB\n",
       "398        you     PRP     PRON\n",
       "399        for      IN      ADP\n",
       "400  listening     VBG     VERB\n",
       "401          .       .    PUNCT\n",
       "\n",
       "[402 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>local</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newspaper,</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>think</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>effects</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>computers</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>on</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>people</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>great</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>learning</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>skills/affects</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>because</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>give</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>us</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>time</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>chat</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>with</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>friends/new</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>people,</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>helps</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>us</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>learn</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>about</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>globe(astronomy)</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>child</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>because</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>it</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>gives</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>us</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>time</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>chat</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>with</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>friends/new</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>people,</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>helps</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>us</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>learn</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>about</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>globe</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>believe</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>or</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>not</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>keeps</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>us</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>out</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>troble.</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Thank</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>you</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>for</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>listening.</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Word POS tag\n",
       "0                Dear     NNP\n",
       "1               local      JJ\n",
       "2          newspaper,      NN\n",
       "3                   I     PRP\n",
       "4               think     VBP\n",
       "5             effects     NNS\n",
       "6           computers     NNS\n",
       "7                have     VBP\n",
       "8                  on      IN\n",
       "9              people     NNS\n",
       "10                are     VBP\n",
       "11              great      JJ\n",
       "12           learning      JJ\n",
       "13     skills/affects     NNS\n",
       "14            because      IN\n",
       "15               they     PRP\n",
       "16               give     VBP\n",
       "17                 us     PRP\n",
       "18               time      NN\n",
       "19                 to      TO\n",
       "20               chat      VB\n",
       "21               with      IN\n",
       "22        friends/new      JJ\n",
       "23            people,      NN\n",
       "24              helps     VBZ\n",
       "25                 us     PRP\n",
       "26              learn      VB\n",
       "27              about      IN\n",
       "28                the      DT\n",
       "29   globe(astronomy)      NN\n",
       "..                ...     ...\n",
       "308             child      VB\n",
       "309           because      IN\n",
       "310                it     PRP\n",
       "311             gives     VBZ\n",
       "312                us     PRP\n",
       "313              time      NN\n",
       "314                to      TO\n",
       "315              chat      VB\n",
       "316              with      IN\n",
       "317       friends/new      JJ\n",
       "318           people,      NN\n",
       "319             helps     VBZ\n",
       "320                us     PRP\n",
       "321             learn      VB\n",
       "322             about      IN\n",
       "323               the      DT\n",
       "324             globe      NN\n",
       "325               and      CC\n",
       "326           believe     VBP\n",
       "327                or      CC\n",
       "328               not      RB\n",
       "329             keeps      VB\n",
       "330                us     PRP\n",
       "331               out      IN\n",
       "332                of      IN\n",
       "333           troble.      NN\n",
       "334             Thank     NNP\n",
       "335               you     PRP\n",
       "336               for      IN\n",
       "337        listening.      NN\n",
       "\n",
       "[338 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORGANIZATION2 GPE\n",
      "DATE1 ORG\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x1a42ac9a60>, {'Dear': {'costly', 'beloved', 'dear'}, 'local': {'local', 'local_anesthetic'}, 'newspaper': {'newspaper'}, 'I': {'I', 'iodine', 'one'}, 'think': {'think'}, 'effects': {'effects', 'effect', 'consequence', 'impression'}, 'computers': {'computer', 'calculator'}, 'people': {'citizenry', 'people', 'multitude'}, 'great': {'bang-up', 'big', 'great', 'capital'}, 'learning': {'eruditeness', 'learning'}, 'give': {'give'}, 'us': {'U', 'United_States', 'uracil', 'uranium'}, 'time': {'clock_time', 'prison_term', 'time', 'meter', 'fourth_dimension'}, 'chat': {'New_World_chat', 'Old_World_chat', 'chat'}, 'helps': {'avail', 'assistant', 'aid'}, 'globe': {'Earth', 'globe', 'ball'}, 'astronomy': {'astronomy'}, 'keeps': {'support', 'keep', 'hold'}, 'Thing': {'matter', 'thing'}, 'feel': {'feel', 'spirit', 'tactile_property'}, 'teenager': {'adolescent'}, 'phone': {'telephone', 'phone', 'earphone'}, 'friends': {'ally', 'friend', 'Friend', 'acquaintance', 'supporter'}, 'Do': {'bash', 'Doctor_of_Osteopathy', 'do'}, 'partner': {'spouse', 'collaborator', 'partner'}, 'things': {'things', 'matter', 'thing'}, 'Well': {'well'}, 'way': {'way', 'manner', 'means', 'room', 'direction'}, 'plenty': {'plenty', 'batch'}, 'sites': {'site', 'web_site'}, 'internet': {'internet'}, 'ect': {'electroconvulsive_therapy'}, 'setting': {'mount', 'context', 'place_setting', 'mise_en_scene', 'setting'}, 'meeting': {'merging', 'meeting', 'confluence'}, 'boss': {'knob', 'party_boss', 'boss', 'foreman', 'Bos'}, 'computer': {'computer', 'calculator'}, 'fun': {'fun', 'playfulness'}, 'rushing': {'haste', 'rush'}, 'get': {'get'}, 'cause': {'campaign', 'cause', 'causal_agent', 'lawsuit'}, 'want': {'privation', 'lack', 'need', 'wish'}, 'use': {'function', 'consumption', 'use', 'habit', 'manipulation'}, 'outside': {'outside'}, 'going': {'going', 'departure', 'passing'}, 'might': {'might'}, 'child': {'child'}, 'lot': {'lot', 'set', 'bunch', 'batch', 'fortune', 'draw', 'Lot'}, 'question': {'motion', 'doubt', 'question'}, 'economy': {'economy'}, 'sea': {'ocean', 'sea'}, 'floor': {'floor'}, 'spreading': {'spread', 'dissemination'}, 'even': {'evening'}, 'surprise': {'surprise'}, 'much': {'much'}, 'knows': {'know'}, 'class': {'class', 'course'}, 'day': {'day', 'sidereal_day', 'Day'}, 'reading': {'recitation', 'interpretation', 'Reading', 'reading'}, 'books': {'script', 'Koran', 'ledger', 'book', 'Bible', 'record'}, 'home': {'dwelling', 'home_plate', 'home', 'base', 'family'}, 'better': {'better', 'bettor'}, 'know': {'know'}, 'right': {'right', 'veracious', 'good', 'proper', 'correct'}, 'hospital': {'hospital'}, 'bed': {'layer', 'bed', 'seam'}, 'playing': {'playing', 'acting'}, 'games': {'game', 'plot'}, 'safe': {'condom', 'safe'}, 'sound': {'audio', 'phone', 'strait', 'sound'}, 'community': {'residential_district', 'community'}, 'place': {'plaza', 'stead', 'home', 'position', 'seat', 'topographic_point', 'place', 'space'}, 'Now': {'now'}, 'hope': {'Hope', 'hope', 'promise'}, 'point': {'distributor_point', 'compass_point', 'decimal_point', 'point', 'detail', 'period', 'degree', 'item'}, 'gives': {'give'}, 'listening': {'listening'}})\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "word_syns = defaultdict(lambda: set())\n",
    "for word_index,word in enumerate(s0):\n",
    "    if word not in stop_words:\n",
    "        word_pos = doc[word_index].pos_\n",
    "        if word_pos == \"ADJ\":\n",
    "            syns = wordnet.synsets(word,wordnet.ADJ)\n",
    "        elif word_pos == \"NOUN\" or \"PROPN\":\n",
    "            syns = wordnet.synsets(word,wordnet.NOUN)\n",
    "        elif word_pos == \"ADV\":\n",
    "            syns = wordnet.synsets(word,wordnet.ADV)\n",
    "        else:\n",
    "            continue\n",
    "            #if word not in stop_words:\n",
    "            #or word_pos == \"NOUN\" or word_pos == \"VERB\"\n",
    "        for i in range(len(syns)):\n",
    "            word_syns[word].add(syns[i].lemmas()[0].name())\n",
    "\n",
    "print(word_syns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x1a42d03e18>, {'Dear': {'thank', 'dear'}, 'local': {'local', 'businesses', 'locally', 'regional'}, 'newspaper': {'tabloid', 'newspapers', 'magazine', 'newspaper'}, 'effects': {'effects', 'adverse', 'affect', 'effect'}, 'computers': {'laptops', 'computers', 'desktops', 'computer'}, 'people': {'individuals', 'those', 'people', 'others'}, 'great': {'fantastic', 'good', 'great', 'wonderful'}, 'learning': {'learn', 'teach', 'teaching', 'learning'}, 'skills/affects': {'educated', 'wade', 'eradicate', 'equator'}, 'chat': {'chatroom', 'chatting', 'chat', 'chats'}, ',': {'and', ',', ';'}, 'us': {'our', 'us', 'we', 'them'}, 'learn': {'understand', 'teach', 'learn', 'learning'}, '!': {':)', '!', ':-)', ';)'}, 'How': {'what', 'how'}, 'feel': {'felt', 'feels', 'feel', 'feeling'}, 'phone': {'phone', 'cellphone', 'phones', 'telephone'}, 'friends': {'buddies', 'pals', 'friend', 'friends'}, 'time': {'day', 'time', 'once', 'when'}, 'things': {'things', 'everything', 'something', 'thing'}, 'Well': {'but', 'well'}, 'new': {'newly', 'newest', 'new', 'latest'}, 'computer': {'software', 'computer', 'laptop', 'computers'}, 'sites': {'site', 'web', 'sites', 'websites'}, 'internet': {'online', 'web', 'websites', 'internet'}, '@': {'@', 'pm', 'at'}, 'facebook': {'fb', 'google', 'twitter', 'facebook'}, 'ect': {'whatnot', 'etc', 'anyways', 'ect'}, 'Just': {'just', 'actually'}, 'setting': {'settings', 'setting', 'set', 'changing'}, 'meeting': {'meeting', 'conference', 'committee', 'meetings'}, 'rushing': {'rushes', 'touchdowns', 'rushing', 'rushed'}, 'cause': {'causing', 'cause', 'caused', 'causes'}, '?': {'....', '?', '!', 'anyway'}, 'think': {'guess', 'thought', 'think', 'know'}, 'lot': {'lot', 'some', 'lots', 'much'}, 'question': {'questions', 'answer', 'problem', 'question'}, 'economy': {'economy', 'economies', 'recession', 'economic'}, \"'s\": {'s', 'own', 'his', \"'s\"}, 'surprise': {'surprising', 'surprised', 'surprises', 'surprise'}, 'much': {'so', 'even', 'too', 'much'}, 'he/she': {'him/her', 'she/he', 's/he', 'he/she'}, 'reading': {'books', 'reading', 'read', 'writing'}, '.': {'....', '.', '...', 'so'}, 'If': {'if', 'unless'}, 'library': {'libraries', 'library', 'bookstore', 'librarian'}, 'fresh': {'tasty', 'freshly', 'delicious', 'fresh'}, 'perpressured': {'educated', 'wade', 'eradicate', 'equator'}, 'know': {'what', 'think', 'tell', 'know'}, 'right': {'way', 'right', 'you', 'just'}, 'CAPS2': {'sonny', 'peasant', 'vivi', 'concentrate'}, 'hospital': {'medical', 'hospitals', 'clinic', 'hospital'}, 'playing': {'plays', 'play', 'playing', 'played'}, 'sound': {'sounded', 'sounding', 'sounds', 'sound'}, 'home': {'home', 'living', 'house', 'homes'}, 'Now': {'now', 'already'}, 'hope': {'hope', 'glad', 'hopefully', 'hoping'}, 'understand': {'explain', 'understand', 'realize', 'know'}, 'agree': {'think', 'disagree', 'believe', 'agree'}, 'friends/new': {'educated', 'wade', 'eradicate', 'equator'}, 'believe': {'think', 'say', 'why', 'believe'}, 'troble': {'forsee', 'shotting', 'probs', 'shitton'}})\n"
     ]
    }
   ],
   "source": [
    "# Use spacy instead of wordnet\n",
    "word_syns_spacy = defaultdict(lambda: set())\n",
    "for word_index,word in enumerate(s0):\n",
    "    if word not in stop_words:\n",
    "        word_pos = doc[word_index].pos_\n",
    "        if word_pos == \"ADJ\" or word_pos == \"NOUN\" or word_pos == \"PROPN\" or word_pos == \"ADV\":\n",
    "            word_syn_list = [w.lower_ for w in most_similar(nlp.vocab[word])]\n",
    "            for syn_w in word_syn_list:\n",
    "                word_syns_spacy[word].add(syn_w)\n",
    "\n",
    "print(word_syns_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('safe.n.01'), Synset('safe.n.02'), Synset('condom.n.01')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets('safe',wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
