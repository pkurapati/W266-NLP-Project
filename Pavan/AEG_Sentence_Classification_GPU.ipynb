{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import json, os, re, shutil, sys, time\n",
    "import seaborn as sns\n",
    "from importlib import reload\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "from collections import defaultdict\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Import spacy\n",
    "import spacy\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NumPy, Pandas and TensorFlow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "from numpy.random import seed\n",
    "from pandas import read_csv, DataFrame\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Activation, Dropout, Conv1D, MaxPooling1D, Bidirectional, Flatten, TimeDistributed\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import keras.backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEG Long Essay Sentence Level Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score      ...        \\\n",
       "0             NaN             NaN            NaN      ...         \n",
       "1             NaN             NaN            NaN      ...         \n",
       "2             NaN             NaN            NaN      ...         \n",
       "3             NaN             NaN            NaN      ...         \n",
       "4             NaN             NaN            NaN      ...         \n",
       "\n",
       "   rater2_trait3  rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "aeg_long = pd.read_csv(\"../data-DNC/AEG/training_set_rel3.tsv\",sep='\\t',encoding = \"latin1\")\n",
    "aeg_long.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test. We need to do this first to ensure that when we split to \n",
    "# sentence level, we have sentences of a given essay in either training or test but not on both.\n",
    "\n",
    "tr_essay,ts_essay,tr_domain_score,ts_domain_score,tr_essay_id,ts_essay_id,tr_essay_set,ts_essay_set=train_test_split(\n",
    "    np.asarray(aeg_long.essay),np.asarray(aeg_long.domain1_score),\n",
    "    np.asarray(aeg_long.essay_id),np.asarray(aeg_long.essay_set),test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10380,)\n",
      "(2596,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of training and test datasets\n",
    "print(tr_essay.shape)\n",
    "print(ts_essay.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test data frames with relevant fields\n",
    "\n",
    "x_train_df = pd.DataFrame([tr_essay_id,tr_essay_set,tr_essay,tr_domain_score.astype(np.double)]).transpose()\n",
    "x_train_df.columns = ['essay_id','essay_set','essay','domain1_score']\n",
    "x_test_df = pd.DataFrame([ts_essay_id,ts_essay_set,ts_essay,ts_domain_score.astype(np.double)]).transpose()\n",
    "x_test_df.columns = ['essay_id','essay_set','essay','domain1_score']\n",
    "#print(x_train_df.head(5))\n",
    "#print(x_test_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split essay into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use spacy to split the essay into sentences. \n",
    "# Load spacy large english module\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to split essay into sentences\n",
    "def create_sentences_df(df):\n",
    "    \"\"\" Function to split essay data into individual sentences. Returns a dataframe\"\"\"\n",
    "    start=datetime.now()\n",
    "    aeg_long_sentence = pd.DataFrame(columns=['essay_id','essay_set','sentence','domain1_score'])\n",
    "    for i in range(len(df)):\n",
    "        if i%1000 == 0:\n",
    "            print(\"At iteration :\",i)\n",
    "            print(\"Duration: \",datetime.now()-start)\n",
    "        sentence = nlp(df.essay[i])\n",
    "        for s in sentence.sents:\n",
    "            aeg_long_sentence = aeg_long_sentence.append({'essay_id' : df.essay_id[i],\n",
    "                                                          'essay_set' : df.essay_set[i],'sentence' : s.text, \n",
    "                                                          'domain1_score' : df.domain1_score[i]},\n",
    "                                                         ignore_index=True)\n",
    "    return aeg_long_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration : 0\n",
      "Duration:  0:00:00.004551\n",
      "At iteration : 1000\n",
      "Duration:  0:01:45.409653\n",
      "At iteration : 2000\n",
      "Duration:  0:04:20.453870\n",
      "At iteration : 3000\n",
      "Duration:  0:07:43.922045\n",
      "At iteration : 4000\n",
      "Duration:  0:11:32.393720\n",
      "At iteration : 5000\n",
      "Duration:  0:16:11.581768\n",
      "At iteration : 6000\n",
      "Duration:  0:21:47.227340\n",
      "At iteration : 7000\n",
      "Duration:  0:28:03.155920\n",
      "At iteration : 8000\n",
      "Duration:  0:35:43.530792\n",
      "At iteration : 9000\n",
      "Duration:  0:44:05.430469\n",
      "At iteration : 10000\n",
      "Duration:  0:53:15.997550\n"
     ]
    }
   ],
   "source": [
    "# Split train data into sentences\n",
    "x_train_sentence_df = create_sentences_df(x_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration : 0\n",
      "Duration:  0:00:00.003777\n",
      "At iteration : 1000\n",
      "Duration:  0:01:42.543824\n",
      "At iteration : 2000\n",
      "Duration:  0:04:14.396282\n"
     ]
    }
   ],
   "source": [
    "# Split test data into sentences\n",
    "x_test_sentence_df = create_sentences_df(x_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each essay set has a different scoring range. We need to normalize the scores to a standard scale for training.\n",
    "def normalize_score(essay):\n",
    "    \"\"\" Normalizes the domain score based on percentage\"\"\"\n",
    "    score = 0\n",
    "    score = float(essay[3])\n",
    "    essay_set = essay[1]\n",
    "    if essay_set == 1:\n",
    "        div = 12\n",
    "    elif essay_set == 2:\n",
    "        div = 5\n",
    "    elif essay_set == 3:\n",
    "        div = 3\n",
    "    elif essay_set == 4:\n",
    "        div = 3\n",
    "    elif essay_set == 5:\n",
    "        div = 4\n",
    "    elif essay_set == 6:\n",
    "        div = 4\n",
    "    elif essay_set == 7:\n",
    "        div = 25\n",
    "    elif essay_set == 8:\n",
    "        div = 50\n",
    "    return score/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sentence_df['Norm_Score'] = x_train_sentence_df.apply(normalize_score,axis=1)\n",
    "x_test_sentence_df['Norm_Score'] = x_test_sentence_df.apply(normalize_score,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>sentence</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>Norm_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>Imagine standing outside, the warm sun dancing...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>But no, that won't happen.</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>Because children and their parents are spendin...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>People aren't getting enough excercise, it can...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>I think people need to realize that computers ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id essay_set                                           sentence  \\\n",
       "0      159         1  Imagine standing outside, the warm sun dancing...   \n",
       "1      159         1                         But no, that won't happen.   \n",
       "2      159         1  Because children and their parents are spendin...   \n",
       "3      159         1  People aren't getting enough excercise, it can...   \n",
       "4      159         1  I think people need to realize that computers ...   \n",
       "\n",
       "   domain1_score  Norm_Score  \n",
       "0           10.0    0.833333  \n",
       "1           10.0    0.833333  \n",
       "2           10.0    0.833333  \n",
       "3           10.0    0.833333  \n",
       "4           10.0    0.833333  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sentence_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this dataset in pickle format so that we don't have to redo the above steps.\n",
    "import pickle\n",
    "x_train_sentence_df.to_pickle(\"./x_train_sentence_df.pkl\")\n",
    "x_test_sentence_df.to_pickle(\"./x_test_sentence_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147026,)\n",
      "(147026,)\n",
      "(36875,)\n",
      "(36875,)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test text and labels\n",
    "\n",
    "x_train = x_train_sentence_df['sentence'].values\n",
    "y_train = x_train_sentence_df['Norm_Score'].values\n",
    "x_test = x_test_sentence_df['sentence'].values\n",
    "y_test = x_test_sentence_df['Norm_Score'].values\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "train_data = pad_sequences(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_class = train_data.shape[1]\n",
    "max_words_class = vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36875, 175)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "test_data = pad_sequences(test_seq, maxlen=max_len_class)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1917494 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('/home/pkurapati/W266-NLP-Project/data-DNC/glove.42B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocabulary_size, 300))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(actual, predict):\n",
    "    diff = actual - predict\n",
    "    diff = sum(diff**2) / len(actual)\n",
    "    return np.sqrt(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cohen Kappa score as defined by the kaggle challenge/wikipedia\n",
    "def CohenKappa(actual, predict):\n",
    "    CohenDF = pd.DataFrame([actual.astype(np.double).round(), np.around(predict.astype(np.double))]).transpose()\n",
    "    count = len(CohenDF)\n",
    "    CohenDF.columns = ['actual','predict']\n",
    "    correct = len(CohenDF[CohenDF.actual==CohenDF.predict])\n",
    "    acc = correct / count\n",
    "    pe = 0\n",
    "    for value in CohenDF.actual.unique():\n",
    "        pe += len(CohenDF[CohenDF.actual == value]) * len(CohenDF[CohenDF.predict == value])\n",
    "    pe = pe / np.square(count)\n",
    "    return(1 - (1-acc)/(1-pe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definitions\n",
    "\n",
    "def CNN_lstm():\n",
    "    \"\"\" CNN with single layer LSTM\"\"\"\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], trainable=False))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_conv.add(tf.keras.layers.Conv1D(64, 5, activation='relu'))\n",
    "    model_conv.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "    model_conv.add(tf.keras.layers.LSTM(100))\n",
    "    model_conv.add(tf.keras.layers.Dense(100))\n",
    "    model_conv.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    #sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "    model_conv.compile(loss = 'mse', optimizer = tf.train.AdamOptimizer(), metrics = ['accuracy'])\n",
    "    #model_conv.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "def stack_lstm():\n",
    "    \"\"\" Stacked LSTM\"\"\"\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], trainable=False))\n",
    "    #model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    #model_conv.add(tf.keras.layers.Conv1D(64, 5, activation='relu'))\n",
    "    #model_conv.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "    #model_conv.add(tf.keras.layers.Dropout(0.2))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32,return_sequences=True))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32, return_sequences=True))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.2))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32))\n",
    "    model_conv.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    #sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "    model_conv.compile(loss = 'mse', optimizer = tf.train.AdamOptimizer(), metrics = ['accuracy'])\n",
    "    #model_conv.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "def stateful_stacked_lstm():\n",
    "    # In stateful, total samples needs to be divisible by batch size\n",
    "    # we have 147026 samples, so selecting 6683 (6683*22=147026)\n",
    "    batch_size=6683\n",
    "    model_conv = Sequential()\n",
    "    # In stateful, we have to pass batch_input_shape to the first layer\n",
    "    model_conv.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], \n",
    "                                             trainable=False,batch_input_shape=(batch_size,max_len_class)))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32,stateful=True,return_sequences=True))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_conv.add(tf.keras.layers.Dense(100))\n",
    "    model_conv.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    #sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "    model_conv.compile(loss = 'mse', optimizer = tf.train.AdamOptimizer(), metrics = ['accuracy'])\n",
    "    #model_conv.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "#bidirectional RNN is screwed up atm\n",
    "def Bidirectional_RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len_class])\n",
    "    layer = Embedding(max_words,200,input_length=max_len_class)(inputs)\n",
    "    layer = Bidirectional(LSTM(10))(layer)\n",
    "    layer = Dense(32,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n",
    "\n",
    "def feedforward_NN():\n",
    "    model_ff = Sequential()\n",
    "    model_ff.add(tf.keras.layers.Embedding(max_words_class,200,input_length=max_len_class))\n",
    "    model_ff.add(tf.keras.layers.Flatten())\n",
    "    model_ff.add(tf.keras.layers.Dense(50,activation='tanh'))\n",
    "    model_ff.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "    model_ff.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_ff\n",
    "\n",
    "def RNN():\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(tf.keras.layers.Embedding(max_words_class,200,input_length=max_len_class))\n",
    "    model_rnn.add(tf.keras.layers.LSTM(10))\n",
    "    model_rnn.add(tf.keras.layers.Dense(1,name='out_layer'))\n",
    "    model_rnn.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(build_fn=CNN_lstm, epochs=20, batch_size=500)\n",
    "#kfold = KFold(n_splits=5, random_state=43)\n",
    "#results = np.sqrt(-1*cross_val_score(estimator, train_data, train_y_sentence,scoring= \"neg_mean_squared_error\", cv=kfold))\n",
    "#print(\"Training RMSE mean and std from CV: {} {}\".format(results.mean(),results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "147026/147026 [==============================] - 44s 297us/step - loss: 0.0377 - acc: 0.0995\n",
      "Epoch 2/20\n",
      "147026/147026 [==============================] - 26s 177us/step - loss: 0.0286 - acc: 0.1016\n",
      "Epoch 3/20\n",
      "147026/147026 [==============================] - 26s 174us/step - loss: 0.0279 - acc: 0.1021\n",
      "Epoch 4/20\n",
      "147026/147026 [==============================] - 26s 175us/step - loss: 0.0271 - acc: 0.1026\n",
      "Epoch 5/20\n",
      "147026/147026 [==============================] - 27s 181us/step - loss: 0.0264 - acc: 0.1032\n",
      "Epoch 6/20\n",
      "147026/147026 [==============================] - 26s 176us/step - loss: 0.0259 - acc: 0.1034\n",
      "Epoch 7/20\n",
      "147026/147026 [==============================] - 26s 179us/step - loss: 0.0252 - acc: 0.1038\n",
      "Epoch 8/20\n",
      "147026/147026 [==============================] - 26s 178us/step - loss: 0.0245 - acc: 0.1041\n",
      "Epoch 9/20\n",
      "147026/147026 [==============================] - 26s 175us/step - loss: 0.0238 - acc: 0.1045\n",
      "Epoch 10/20\n",
      "147026/147026 [==============================] - 26s 178us/step - loss: 0.0235 - acc: 0.1046\n",
      "Epoch 11/20\n",
      "147026/147026 [==============================] - 26s 176us/step - loss: 0.0230 - acc: 0.1049\n",
      "Epoch 12/20\n",
      "147026/147026 [==============================] - 26s 178us/step - loss: 0.0223 - acc: 0.1051\n",
      "Epoch 13/20\n",
      "147026/147026 [==============================] - 26s 175us/step - loss: 0.0219 - acc: 0.1053\n",
      "Epoch 14/20\n",
      "147026/147026 [==============================] - 26s 178us/step - loss: 0.0216 - acc: 0.1055\n",
      "Epoch 15/20\n",
      "147026/147026 [==============================] - 26s 174us/step - loss: 0.0212 - acc: 0.1056\n",
      "Epoch 16/20\n",
      "147026/147026 [==============================] - 26s 176us/step - loss: 0.0210 - acc: 0.1059\n",
      "Epoch 17/20\n",
      "147026/147026 [==============================] - 26s 180us/step - loss: 0.0208 - acc: 0.1059\n",
      "Epoch 18/20\n",
      "147026/147026 [==============================] - 26s 176us/step - loss: 0.0203 - acc: 0.1060\n",
      "Epoch 19/20\n",
      "147026/147026 [==============================] - 26s 176us/step - loss: 0.0200 - acc: 0.1061\n",
      "Epoch 20/20\n",
      "147026/147026 [==============================] - 26s 175us/step - loss: 0.0198 - acc: 0.1062\n",
      "RMSE:  0.17643804092942159\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(train_data, y_train)\n",
    "prediction_cnn_glove=estimator.predict(test_data)\n",
    "rmse_val = RMSE(y_test,prediction_cnn_glove)\n",
    "print(\"RMSE: \",rmse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get the multiplication factor. We can get it back from the essay set, but\n",
    "# it is better to do it from the score, because there are scores with value 0, and its MF should be 0\n",
    "\n",
    "def find_mult_factor(x):\n",
    "    \"\"\" Function to find the multiplication factor for denormalizing\"\"\"\n",
    "    if x[1] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.around(x[0]/x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig_Score</th>\n",
       "      <th>Norm_Score</th>\n",
       "      <th>Pred_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.709597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.732755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.738980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.665324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.712178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.695024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.660436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.751960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.727825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.757067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Orig_Score  Norm_Score  Pred_Score\n",
       "0         9.0        0.75    0.709597\n",
       "1         9.0        0.75    0.732755\n",
       "2         9.0        0.75    0.738980\n",
       "3         9.0        0.75    0.665324\n",
       "4         9.0        0.75    0.712178\n",
       "5         9.0        0.75    0.695024\n",
       "6         9.0        0.75    0.660436\n",
       "7         9.0        0.75    0.751960\n",
       "8         9.0        0.75    0.727825\n",
       "9         9.0        0.75    0.757067"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df = pd.DataFrame([x_test_sentence_df['domain1_score'].astype(np.double), y_test.astype(np.double),\n",
    "                      prediction_cnn_glove.astype(np.double)]).transpose()\n",
    "cnn_df.columns = ['Orig_Score','Norm_Score','Pred_Score']\n",
    "cnn_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig_Score</th>\n",
       "      <th>Norm_Score</th>\n",
       "      <th>Pred_Score</th>\n",
       "      <th>Mult_Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.709597</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.732755</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.738980</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.665324</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.712178</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.695024</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.660436</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.751960</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.727825</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.757067</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Orig_Score  Norm_Score  Pred_Score  Mult_Factor\n",
       "0         9.0        0.75    0.709597         12.0\n",
       "1         9.0        0.75    0.732755         12.0\n",
       "2         9.0        0.75    0.738980         12.0\n",
       "3         9.0        0.75    0.665324         12.0\n",
       "4         9.0        0.75    0.712178         12.0\n",
       "5         9.0        0.75    0.695024         12.0\n",
       "6         9.0        0.75    0.660436         12.0\n",
       "7         9.0        0.75    0.751960         12.0\n",
       "8         9.0        0.75    0.727825         12.0\n",
       "9         9.0        0.75    0.757067         12.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df['Mult_Factor'] = cnn_df.apply(find_mult_factor,axis=1)\n",
    "cnn_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig_Score</th>\n",
       "      <th>Norm_Score</th>\n",
       "      <th>Pred_Score</th>\n",
       "      <th>Mult_Factor</th>\n",
       "      <th>Denorm_Pred_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.709597</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.732755</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.738980</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.665324</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.712178</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.695024</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.660436</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.751960</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.727825</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.757067</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Orig_Score  Norm_Score  Pred_Score  Mult_Factor  Denorm_Pred_Score\n",
       "0         9.0        0.75    0.709597         12.0                9.0\n",
       "1         9.0        0.75    0.732755         12.0                9.0\n",
       "2         9.0        0.75    0.738980         12.0                9.0\n",
       "3         9.0        0.75    0.665324         12.0                8.0\n",
       "4         9.0        0.75    0.712178         12.0                9.0\n",
       "5         9.0        0.75    0.695024         12.0                8.0\n",
       "6         9.0        0.75    0.660436         12.0                8.0\n",
       "7         9.0        0.75    0.751960         12.0                9.0\n",
       "8         9.0        0.75    0.727825         12.0                9.0\n",
       "9         9.0        0.75    0.757067         12.0                9.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def denormalize(x):\n",
    "    return np.around(x[2] * x[3])\n",
    "cnn_df['Denorm_Pred_Score'] = cnn_df.apply(denormalize,axis=1)\n",
    "cnn_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  3.215597580016842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orig_score = cnn_df.Orig_Score.as_matrix(columns=None)\n",
    "orig_score = orig_score.astype(np.int)\n",
    "pred_score = cnn_df.Denorm_Pred_Score.as_matrix(columns=None)\n",
    "pred_score = pred_score.astype(np.int)\n",
    "rmse_cnn = RMSE(orig_score,pred_score)\n",
    "print(\"RMSE: \",rmse_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen Kappa:  0.24919366467431903\n"
     ]
    }
   ],
   "source": [
    "cohen_kappa = cohen_kappa_score(orig_score,pred_score)\n",
    "print(\"Cohen Kappa: \",cohen_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.3097220338983051\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(orig_score,pred_score)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "147026/147026 [==============================] - 35s 237us/step - loss: 0.1674 - acc: 0.0622\n",
      "Epoch 2/100\n",
      "147026/147026 [==============================] - 31s 208us/step - loss: 0.0330 - acc: 0.1014\n",
      "Epoch 3/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0315 - acc: 0.1014\n",
      "Epoch 4/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0315 - acc: 0.1014\n",
      "Epoch 5/100\n",
      "147026/147026 [==============================] - 31s 212us/step - loss: 0.0315 - acc: 0.1014\n",
      "Epoch 6/100\n",
      "147026/147026 [==============================] - 31s 212us/step - loss: 0.0315 - acc: 0.1014\n",
      "Epoch 7/100\n",
      "147026/147026 [==============================] - 32s 217us/step - loss: 0.0314 - acc: 0.1014\n",
      "Epoch 8/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0314 - acc: 0.1014\n",
      "Epoch 9/100\n",
      "147026/147026 [==============================] - 31s 212us/step - loss: 0.0312 - acc: 0.1014\n",
      "Epoch 10/100\n",
      "147026/147026 [==============================] - 31s 208us/step - loss: 0.0309 - acc: 0.1014\n",
      "Epoch 11/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0300 - acc: 0.1014\n",
      "Epoch 12/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0292 - acc: 0.1014\n",
      "Epoch 13/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0287 - acc: 0.1014\n",
      "Epoch 14/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0284 - acc: 0.1015\n",
      "Epoch 15/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0282 - acc: 0.1017\n",
      "Epoch 16/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0280 - acc: 0.1019\n",
      "Epoch 17/100\n",
      "147026/147026 [==============================] - 32s 216us/step - loss: 0.0278 - acc: 0.1019\n",
      "Epoch 18/100\n",
      "147026/147026 [==============================] - 31s 212us/step - loss: 0.0276 - acc: 0.1021\n",
      "Epoch 19/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0276 - acc: 0.1022\n",
      "Epoch 20/100\n",
      "147026/147026 [==============================] - 31s 213us/step - loss: 0.0274 - acc: 0.1022\n",
      "Epoch 21/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0272 - acc: 0.1024\n",
      "Epoch 22/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0271 - acc: 0.1024\n",
      "Epoch 23/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0271 - acc: 0.1025\n",
      "Epoch 24/100\n",
      "147026/147026 [==============================] - 31s 208us/step - loss: 0.0271 - acc: 0.1026\n",
      "Epoch 25/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0270 - acc: 0.1027\n",
      "Epoch 26/100\n",
      "147026/147026 [==============================] - 31s 208us/step - loss: 0.0268 - acc: 0.1028\n",
      "Epoch 27/100\n",
      "147026/147026 [==============================] - 31s 214us/step - loss: 0.0268 - acc: 0.1028\n",
      "Epoch 28/100\n",
      "147026/147026 [==============================] - 31s 208us/step - loss: 0.0268 - acc: 0.1029\n",
      "Epoch 29/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0265 - acc: 0.1030\n",
      "Epoch 30/100\n",
      "147026/147026 [==============================] - 31s 213us/step - loss: 0.0265 - acc: 0.1030\n",
      "Epoch 31/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0264 - acc: 0.1031\n",
      "Epoch 32/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0263 - acc: 0.1031\n",
      "Epoch 33/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0262 - acc: 0.1033\n",
      "Epoch 34/100\n",
      "147026/147026 [==============================] - 31s 213us/step - loss: 0.0262 - acc: 0.1033\n",
      "Epoch 35/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0261 - acc: 0.1032\n",
      "Epoch 36/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0261 - acc: 0.1034\n",
      "Epoch 37/100\n",
      "147026/147026 [==============================] - 31s 214us/step - loss: 0.0259 - acc: 0.1035\n",
      "Epoch 38/100\n",
      "147026/147026 [==============================] - 31s 213us/step - loss: 0.0259 - acc: 0.1035\n",
      "Epoch 39/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0258 - acc: 0.1036\n",
      "Epoch 40/100\n",
      "147026/147026 [==============================] - 31s 208us/step - loss: 0.0258 - acc: 0.1036\n",
      "Epoch 41/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0257 - acc: 0.1036\n",
      "Epoch 42/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0256 - acc: 0.1036\n",
      "Epoch 43/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0257 - acc: 0.1037\n",
      "Epoch 44/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0255 - acc: 0.1037\n",
      "Epoch 45/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0255 - acc: 0.1038\n",
      "Epoch 46/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0254 - acc: 0.1039\n",
      "Epoch 47/100\n",
      "147026/147026 [==============================] - 32s 217us/step - loss: 0.0255 - acc: 0.1038\n",
      "Epoch 48/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0254 - acc: 0.1039\n",
      "Epoch 49/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0252 - acc: 0.1040\n",
      "Epoch 50/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0252 - acc: 0.1039\n",
      "Epoch 51/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0252 - acc: 0.1039\n",
      "Epoch 52/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0251 - acc: 0.1042\n",
      "Epoch 53/100\n",
      "147026/147026 [==============================] - 31s 213us/step - loss: 0.0251 - acc: 0.1040\n",
      "Epoch 54/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0251 - acc: 0.1040\n",
      "Epoch 55/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0249 - acc: 0.1041\n",
      "Epoch 56/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0249 - acc: 0.1041\n",
      "Epoch 57/100\n",
      "147026/147026 [==============================] - 32s 216us/step - loss: 0.0249 - acc: 0.1042\n",
      "Epoch 58/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0248 - acc: 0.1043\n",
      "Epoch 59/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0248 - acc: 0.1042\n",
      "Epoch 60/100\n",
      "147026/147026 [==============================] - 31s 212us/step - loss: 0.0247 - acc: 0.1044\n",
      "Epoch 61/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0246 - acc: 0.1043\n",
      "Epoch 62/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0247 - acc: 0.1044\n",
      "Epoch 63/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0246 - acc: 0.1044\n",
      "Epoch 64/100\n",
      "147026/147026 [==============================] - 30s 207us/step - loss: 0.0246 - acc: 0.1045\n",
      "Epoch 65/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0245 - acc: 0.1045\n",
      "Epoch 66/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0246 - acc: 0.1044\n",
      "Epoch 67/100\n",
      "147026/147026 [==============================] - 32s 216us/step - loss: 0.0244 - acc: 0.1045\n",
      "Epoch 68/100\n",
      "147026/147026 [==============================] - 31s 208us/step - loss: 0.0244 - acc: 0.1045\n",
      "Epoch 69/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0243 - acc: 0.1045\n",
      "Epoch 70/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0243 - acc: 0.1046\n",
      "Epoch 71/100\n",
      "147026/147026 [==============================] - 31s 212us/step - loss: 0.0241 - acc: 0.1047\n",
      "Epoch 72/100\n",
      "147026/147026 [==============================] - 31s 208us/step - loss: 0.0242 - acc: 0.1046\n",
      "Epoch 73/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0241 - acc: 0.1047\n",
      "Epoch 74/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0241 - acc: 0.1048\n",
      "Epoch 75/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0241 - acc: 0.1048\n",
      "Epoch 76/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0240 - acc: 0.1048\n",
      "Epoch 77/100\n",
      "147026/147026 [==============================] - 32s 216us/step - loss: 0.0241 - acc: 0.1048\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0240 - acc: 0.1047\n",
      "Epoch 79/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0239 - acc: 0.1049\n",
      "Epoch 80/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0238 - acc: 0.1050\n",
      "Epoch 81/100\n",
      "147026/147026 [==============================] - 31s 212us/step - loss: 0.0237 - acc: 0.1050\n",
      "Epoch 82/100\n",
      "147026/147026 [==============================] - 30s 207us/step - loss: 0.0239 - acc: 0.1050\n",
      "Epoch 83/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0236 - acc: 0.1050\n",
      "Epoch 84/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0236 - acc: 0.1051\n",
      "Epoch 85/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0236 - acc: 0.1050\n",
      "Epoch 86/100\n",
      "147026/147026 [==============================] - 30s 206us/step - loss: 0.0235 - acc: 0.1051\n",
      "Epoch 87/100\n",
      "147026/147026 [==============================] - 31s 214us/step - loss: 0.0235 - acc: 0.1052\n",
      "Epoch 88/100\n",
      "147026/147026 [==============================] - 31s 208us/step - loss: 0.0235 - acc: 0.1052\n",
      "Epoch 89/100\n",
      "147026/147026 [==============================] - 31s 208us/step - loss: 0.0238 - acc: 0.1050\n",
      "Epoch 90/100\n",
      "147026/147026 [==============================] - 31s 208us/step - loss: 0.0234 - acc: 0.1053\n",
      "Epoch 91/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0232 - acc: 0.1053\n",
      "Epoch 92/100\n",
      "147026/147026 [==============================] - 31s 214us/step - loss: 0.0233 - acc: 0.1053\n",
      "Epoch 93/100\n",
      "147026/147026 [==============================] - 31s 211us/step - loss: 0.0232 - acc: 0.1053\n",
      "Epoch 94/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0232 - acc: 0.1053\n",
      "Epoch 95/100\n",
      "147026/147026 [==============================] - 31s 212us/step - loss: 0.0231 - acc: 0.1053\n",
      "Epoch 96/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0232 - acc: 0.1053\n",
      "Epoch 97/100\n",
      "147026/147026 [==============================] - 32s 215us/step - loss: 0.0230 - acc: 0.1054\n",
      "Epoch 98/100\n",
      "147026/147026 [==============================] - 31s 209us/step - loss: 0.0232 - acc: 0.1054\n",
      "Epoch 99/100\n",
      "147026/147026 [==============================] - 31s 212us/step - loss: 0.0230 - acc: 0.1055\n",
      "Epoch 100/100\n",
      "147026/147026 [==============================] - 31s 210us/step - loss: 0.0228 - acc: 0.1055\n",
      "RMSE:  0.16791693140939992\n"
     ]
    }
   ],
   "source": [
    "estimator_lstm = KerasRegressor(build_fn=stack_lstm, epochs=100, batch_size=5000)\n",
    "estimator_lstm.fit(train_data, y_train)\n",
    "prediction_lstm=estimator_lstm.predict(test_data)\n",
    "rmse_val_lstm = RMSE(y_test,prediction_lstm)\n",
    "print(\"RMSE: \",rmse_val_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lstm_df = pd.DataFrame([x_test_sentence_df['domain1_score'].astype(np.double), y_test.astype(np.double),\n",
    "                      prediction_lstm.astype(np.double)]).transpose()\n",
    "s_lstm_df.columns = ['Orig_Score','Norm_Score','Pred_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig_Score</th>\n",
       "      <th>Norm_Score</th>\n",
       "      <th>Pred_Score</th>\n",
       "      <th>Mult_Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.697532</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.775524</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.740411</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.737734</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.691238</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.743685</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.722204</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.779992</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.707823</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.765121</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Orig_Score  Norm_Score  Pred_Score  Mult_Factor\n",
       "0         9.0        0.75    0.697532         12.0\n",
       "1         9.0        0.75    0.775524         12.0\n",
       "2         9.0        0.75    0.740411         12.0\n",
       "3         9.0        0.75    0.737734         12.0\n",
       "4         9.0        0.75    0.691238         12.0\n",
       "5         9.0        0.75    0.743685         12.0\n",
       "6         9.0        0.75    0.722204         12.0\n",
       "7         9.0        0.75    0.779992         12.0\n",
       "8         9.0        0.75    0.707823         12.0\n",
       "9         9.0        0.75    0.765121         12.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_lstm_df['Mult_Factor'] = s_lstm_df.apply(find_mult_factor,axis=1)\n",
    "s_lstm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig_Score</th>\n",
       "      <th>Norm_Score</th>\n",
       "      <th>Pred_Score</th>\n",
       "      <th>Mult_Factor</th>\n",
       "      <th>Denorm_Pred_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.697532</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.775524</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.740411</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.737734</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.691238</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.743685</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.722204</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.779992</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.707823</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.765121</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Orig_Score  Norm_Score  Pred_Score  Mult_Factor  Denorm_Pred_Score\n",
       "0         9.0        0.75    0.697532         12.0                9.0\n",
       "1         9.0        0.75    0.775524         12.0                9.0\n",
       "2         9.0        0.75    0.740411         12.0                9.0\n",
       "3         9.0        0.75    0.737734         12.0                8.0\n",
       "4         9.0        0.75    0.691238         12.0                9.0\n",
       "5         9.0        0.75    0.743685         12.0                8.0\n",
       "6         9.0        0.75    0.722204         12.0                8.0\n",
       "7         9.0        0.75    0.779992         12.0                9.0\n",
       "8         9.0        0.75    0.707823         12.0                9.0\n",
       "9         9.0        0.75    0.765121         12.0                9.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_lstm_df['Denorm_Pred_Score'] = cnn_df.apply(denormalize,axis=1)\n",
    "s_lstm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Stacked LSTM ###\n",
      "RMSE :  3.215597580016842\n",
      "Cohen Kappa:  0.24919366467431903\n",
      "Accuracy:  0.3097220338983051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orig_score = s_lstm_df.Orig_Score.as_matrix(columns=None)\n",
    "orig_score = orig_score.astype(np.int)\n",
    "pred_score = s_lstm_df.Denorm_Pred_Score.as_matrix(columns=None)\n",
    "pred_score = pred_score.astype(np.int)\n",
    "rmse_lstm = RMSE(orig_score,pred_score)\n",
    "cohen_kappa = cohen_kappa_score(orig_score,pred_score)\n",
    "accuracy = accuracy_score(orig_score,pred_score)\n",
    "print(\"### Stacked LSTM ###\")\n",
    "print(\"RMSE : \",rmse_lstm)\n",
    "print(\"Cohen Kappa: \",cohen_kappa)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen Kappa:  0.24919366467431903\n"
     ]
    }
   ],
   "source": [
    "cohen_kappa = cohen_kappa_score(orig_score,pred_score)\n",
    "print(\"Cohen Kappa: \",cohen_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.3097220338983051\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(orig_score,pred_score)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "147026/147026 [==============================] - 17s 115us/step - loss: 0.1532 - acc: 0.0651\n",
      "Epoch 2/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0470 - acc: 0.0965\n",
      "Epoch 3/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0381 - acc: 0.0991\n",
      "Epoch 4/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0350 - acc: 0.1012\n",
      "Epoch 5/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0341 - acc: 0.1013\n",
      "Epoch 6/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0336 - acc: 0.1014\n",
      "Epoch 7/100\n",
      "147026/147026 [==============================] - 14s 92us/step - loss: 0.0332 - acc: 0.1014\n",
      "Epoch 8/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0329 - acc: 0.1014\n",
      "Epoch 9/100\n",
      "147026/147026 [==============================] - 14s 95us/step - loss: 0.0324 - acc: 0.1014\n",
      "Epoch 10/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0319 - acc: 0.1014\n",
      "Epoch 11/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0316 - acc: 0.1014\n",
      "Epoch 12/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0312 - acc: 0.1014\n",
      "Epoch 13/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0308 - acc: 0.1014\n",
      "Epoch 14/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0304 - acc: 0.1015\n",
      "Epoch 15/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0302 - acc: 0.1016\n",
      "Epoch 16/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0300 - acc: 0.1016\n",
      "Epoch 17/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0297 - acc: 0.1018\n",
      "Epoch 18/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0296 - acc: 0.1019\n",
      "Epoch 19/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0294 - acc: 0.1021\n",
      "Epoch 20/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0293 - acc: 0.1019\n",
      "Epoch 21/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0291 - acc: 0.1021\n",
      "Epoch 22/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0290 - acc: 0.1021\n",
      "Epoch 23/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0289 - acc: 0.1021\n",
      "Epoch 24/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0286 - acc: 0.1022\n",
      "Epoch 25/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0286 - acc: 0.1023\n",
      "Epoch 26/100\n",
      "147026/147026 [==============================] - 13s 92us/step - loss: 0.0284 - acc: 0.1023\n",
      "Epoch 27/100\n",
      "147026/147026 [==============================] - 13s 88us/step - loss: 0.0284 - acc: 0.1025\n",
      "Epoch 28/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0282 - acc: 0.1026\n",
      "Epoch 29/100\n",
      "147026/147026 [==============================] - 13s 88us/step - loss: 0.0281 - acc: 0.1026\n",
      "Epoch 30/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0280 - acc: 0.1026\n",
      "Epoch 31/100\n",
      "147026/147026 [==============================] - 14s 93us/step - loss: 0.0279 - acc: 0.1027\n",
      "Epoch 32/100\n",
      "147026/147026 [==============================] - 14s 93us/step - loss: 0.0278 - acc: 0.1027\n",
      "Epoch 33/100\n",
      "147026/147026 [==============================] - 14s 93us/step - loss: 0.0277 - acc: 0.1028\n",
      "Epoch 34/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0275 - acc: 0.1028\n",
      "Epoch 35/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0275 - acc: 0.1029\n",
      "Epoch 36/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0275 - acc: 0.1029\n",
      "Epoch 37/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0273 - acc: 0.1030\n",
      "Epoch 38/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0272 - acc: 0.1030\n",
      "Epoch 39/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0271 - acc: 0.1030\n",
      "Epoch 40/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0271 - acc: 0.1031\n",
      "Epoch 41/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0269 - acc: 0.1032\n",
      "Epoch 42/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0269 - acc: 0.1032\n",
      "Epoch 43/100\n",
      "147026/147026 [==============================] - 14s 92us/step - loss: 0.0268 - acc: 0.1032\n",
      "Epoch 44/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0268 - acc: 0.1033\n",
      "Epoch 45/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0267 - acc: 0.1033\n",
      "Epoch 46/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0266 - acc: 0.1033\n",
      "Epoch 47/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0265 - acc: 0.1034\n",
      "Epoch 48/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0264 - acc: 0.1034\n",
      "Epoch 49/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0263 - acc: 0.1035\n",
      "Epoch 50/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0263 - acc: 0.1034\n",
      "Epoch 51/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0264 - acc: 0.1033\n",
      "Epoch 52/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0264 - acc: 0.1035\n",
      "Epoch 53/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0262 - acc: 0.1036\n",
      "Epoch 54/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0261 - acc: 0.1036\n",
      "Epoch 55/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0261 - acc: 0.1037\n",
      "Epoch 56/100\n",
      "147026/147026 [==============================] - 14s 96us/step - loss: 0.0261 - acc: 0.1037\n",
      "Epoch 57/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0260 - acc: 0.1036\n",
      "Epoch 58/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0259 - acc: 0.1037\n",
      "Epoch 59/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0259 - acc: 0.1036\n",
      "Epoch 60/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0258 - acc: 0.1037\n",
      "Epoch 61/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0257 - acc: 0.1036\n",
      "Epoch 62/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0257 - acc: 0.1038\n",
      "Epoch 63/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0257 - acc: 0.1037\n",
      "Epoch 64/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0256 - acc: 0.1038\n",
      "Epoch 65/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0255 - acc: 0.1038\n",
      "Epoch 66/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0255 - acc: 0.1039\n",
      "Epoch 67/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0255 - acc: 0.1038\n",
      "Epoch 68/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0255 - acc: 0.1038\n",
      "Epoch 69/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0254 - acc: 0.1039\n",
      "Epoch 70/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0255 - acc: 0.1039\n",
      "Epoch 71/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0253 - acc: 0.1039\n",
      "Epoch 72/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0253 - acc: 0.1039\n",
      "Epoch 73/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0252 - acc: 0.1039\n",
      "Epoch 74/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0251 - acc: 0.1042\n",
      "Epoch 75/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0251 - acc: 0.1041\n",
      "Epoch 76/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0251 - acc: 0.1041\n",
      "Epoch 77/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0251 - acc: 0.1042\n",
      "Epoch 78/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0251 - acc: 0.1041\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147026/147026 [==============================] - 14s 97us/step - loss: 0.0250 - acc: 0.1042\n",
      "Epoch 80/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0249 - acc: 0.1041\n",
      "Epoch 81/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0249 - acc: 0.1042\n",
      "Epoch 82/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0249 - acc: 0.1042\n",
      "Epoch 83/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0249 - acc: 0.1043\n",
      "Epoch 84/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0248 - acc: 0.1043\n",
      "Epoch 85/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0248 - acc: 0.1043\n",
      "Epoch 86/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0248 - acc: 0.1043\n",
      "Epoch 87/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0248 - acc: 0.1043\n",
      "Epoch 88/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0247 - acc: 0.1044\n",
      "Epoch 89/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0247 - acc: 0.1043\n",
      "Epoch 90/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0247 - acc: 0.1043\n",
      "Epoch 91/100\n",
      "147026/147026 [==============================] - 14s 92us/step - loss: 0.0246 - acc: 0.1045\n",
      "Epoch 92/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0246 - acc: 0.1045\n",
      "Epoch 93/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0246 - acc: 0.1043\n",
      "Epoch 94/100\n",
      "147026/147026 [==============================] - 13s 90us/step - loss: 0.0245 - acc: 0.1044\n",
      "Epoch 95/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0245 - acc: 0.1045\n",
      "Epoch 96/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0245 - acc: 0.1044\n",
      "Epoch 97/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0244 - acc: 0.1046\n",
      "Epoch 98/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0244 - acc: 0.1045\n",
      "Epoch 99/100\n",
      "147026/147026 [==============================] - 13s 89us/step - loss: 0.0243 - acc: 0.1046\n",
      "Epoch 100/100\n",
      "147026/147026 [==============================] - 13s 91us/step - loss: 0.0243 - acc: 0.1044\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [3460,32] vs. [6683,32]\n\t [[{{node lstm_14/while/add_3}} = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_14/while/BiasAdd_1, lstm_14/while/MatMul_5)]]\n\t [[{{node dense_9/BiasAdd/_857}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_536_dense_9/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-97e1b8844145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mestimator_stateful_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstateful_stacked_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6683\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mestimator_stateful_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprediction_stateful_lstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator_stateful_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrmse_stateful_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction_stateful_lstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMSE: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrmse_stateful_lstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \"\"\"\n\u001b[1;32m    322\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m       return training_arrays.predict_loop(\n\u001b[0;32m-> 1878\u001b[0;31m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, inputs, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [3460,32] vs. [6683,32]\n\t [[{{node lstm_14/while/add_3}} = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_14/while/BiasAdd_1, lstm_14/while/MatMul_5)]]\n\t [[{{node dense_9/BiasAdd/_857}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_536_dense_9/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "# Ignore this.. For stateful LSTM, our test sample should be a multiple of batch_size\n",
    "# Need to run this again\n",
    "\n",
    "estimator_stateful_lstm = KerasRegressor(build_fn=stateful_stacked_lstm, epochs=100, batch_size=6683)\n",
    "estimator_stateful_lstm.fit(train_data, y_train)\n",
    "prediction_stateful_lstm=estimator_stateful_lstm.predict(test_data)\n",
    "rmse_stateful_lstm = RMSE(y_test,prediction_stateful_lstm)\n",
    "print(\"RMSE: \",rmse_stateful_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating results per essay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>sentence</th>\n",
       "      <th>orig_score</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, @CAPS1 people are talkin...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>People believe that using the computer is a wa...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>I believe that computers aren't a bad thing.</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>Using the computers can help us learn about ot...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>It can also show us the lives about people fro...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>We can also talk to our friends online.</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>If you want to know why computers are useful, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>People say that computers waste our lives.</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>I disagree with that opinion.</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>The internet is a great way to learn about dif...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id essay_set                                           sentence  \\\n",
       "0     1722         1  Dear local newspaper, @CAPS1 people are talkin...   \n",
       "1     1722         1  People believe that using the computer is a wa...   \n",
       "2     1722         1       I believe that computers aren't a bad thing.   \n",
       "3     1722         1  Using the computers can help us learn about ot...   \n",
       "4     1722         1  It can also show us the lives about people fro...   \n",
       "5     1722         1            We can also talk to our friends online.   \n",
       "6     1722         1  If you want to know why computers are useful, ...   \n",
       "7     1722         1         People say that computers waste our lives.   \n",
       "8     1722         1                      I disagree with that opinion.   \n",
       "9     1722         1  The internet is a great way to learn about dif...   \n",
       "\n",
       "  orig_score pred_score  \n",
       "0          9          9  \n",
       "1          9          9  \n",
       "2          9          9  \n",
       "3          9          8  \n",
       "4          9          9  \n",
       "5          9          8  \n",
       "6          9          8  \n",
       "7          9          9  \n",
       "8          9          9  \n",
       "9          9          9  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame([x_test_sentence_df.essay_id.values,x_test_sentence_df.essay_set.values,\n",
    "                         x_test_sentence_df.sentence.values,s_lstm_df.Orig_Score.values,\n",
    "                          s_lstm_df.Denorm_Pred_Score.values]).transpose()\n",
    "result_df.columns = ['essay_id','essay_set','sentence','orig_score','pred_score']\n",
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_min_mean_score(df):\n",
    "    new_df = pd.DataFrame(columns=['essay_id','essay_set','Orig_Score','Max_Score','Min_Score','Mean_Score'])\n",
    "    essay_ids = np.unique(df.essay_id)\n",
    "    for e_id in essay_ids:\n",
    "        df_temp = df[df.essay_id == e_id]\n",
    "        max_score = np.max(df_temp.pred_score)\n",
    "        min_score = np.min(df_temp.pred_score)\n",
    "        # we need to round the mean so that kappa score doesnt complain\n",
    "        mean_score = np.around(np.mean(df_temp.pred_score))\n",
    "        new_df = new_df.append({'essay_id':e_id,'essay_set':int(np.unique(df_temp.essay_set)),\n",
    "                                'Orig_Score':int(np.unique(df_temp.orig_score)),'Max_Score':max_score,\n",
    "                                'Min_Score':min_score,'Mean_Score':mean_score},ignore_index=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2596, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>Orig_Score</th>\n",
       "      <th>Max_Score</th>\n",
       "      <th>Min_Score</th>\n",
       "      <th>Mean_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  Orig_Score  Max_Score  Min_Score  Mean_Score\n",
       "0         2          1           9         10          7           9\n",
       "1         5          1           8         11          6           9\n",
       "2         9          1           9         10          7           9\n",
       "3        14          1           6          9          6           8\n",
       "4        25          1           8         10          8           9\n",
       "5        31          1          10         10          8           9\n",
       "6        33          1           6          9          7           8\n",
       "7        38          1           8         10          8           9\n",
       "8        39          1          10         10          7           8\n",
       "9        41          1           2          9          8           9"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_lstm_test_df = find_max_min_mean_score(result_df)\n",
    "s_lstm_test_df.essay_id = s_lstm_test_df.essay_id.astype(int)\n",
    "s_lstm_test_df.essay_set = s_lstm_test_df.essay_set.astype(int)\n",
    "s_lstm_test_df.Orig_Score = s_lstm_test_df.Orig_Score.astype(int)\n",
    "s_lstm_test_df.Max_Score = s_lstm_test_df.Max_Score.astype(int)\n",
    "s_lstm_test_df.Min_Score = s_lstm_test_df.Min_Score.astype(int)\n",
    "s_lstm_test_df.Mean_Score = s_lstm_test_df.Mean_Score.astype(int)\n",
    "\n",
    "print(s_lstm_test_df.shape)\n",
    "s_lstm_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Stacked_LSTM Results : MAX Score for all Sentence ###\n",
      "RMSE:  3.1274913027854225\n",
      "Cohen Kappa:  0.19453306187010388\n",
      "Accuracy:  0.2842835130970724\n",
      "### Stacked_LSTM Results : Min Score for all Sentence ###\n",
      "RMSE:  3.4656580651219975\n",
      "Cohen Kappa:  0.211439054050241\n",
      "Accuracy:  0.31163328197226503\n",
      "### Stacked_LSTM Results : Mean Score for all Sentence ###\n",
      "RMSE:  2.2545109719516185\n",
      "Cohen Kappa:  0.2981747205219023\n",
      "Accuracy:  0.3882896764252696\n"
     ]
    }
   ],
   "source": [
    "orig_score = s_lstm_test_df.Orig_Score.values\n",
    "max_pred_score = s_lstm_test_df.Max_Score.values\n",
    "min_pred_score = s_lstm_test_df.Min_Score.values\n",
    "mean_pred_score = s_lstm_test_df.Mean_Score.values\n",
    "\n",
    "rmse_max_s_lstm = RMSE(orig_score,max_pred_score)\n",
    "cohen_kappa_max_s_lstm = cohen_kappa_score(orig_score,max_pred_score)\n",
    "accuracy_max_s_lstm = accuracy_score(orig_score,max_pred_score)\n",
    "\n",
    "rmse_min_s_lstm = RMSE(orig_score,min_pred_score)\n",
    "cohen_kappa_min_s_lstm = cohen_kappa_score(orig_score,min_pred_score)\n",
    "accuracy_min_s_lstm = accuracy_score(orig_score,min_pred_score)\n",
    "\n",
    "rmse_mean_s_lstm = RMSE(orig_score,mean_pred_score)\n",
    "cohen_kappa_mean_s_lstm = cohen_kappa_score(orig_score,mean_pred_score)\n",
    "accuracy_mean_s_lstm = accuracy_score(orig_score,mean_pred_score)\n",
    "\n",
    "print(\"### Stacked_LSTM Results : MAX Score for all Sentence ###\")\n",
    "print(\"RMSE: \",rmse_max_s_lstm)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_max_s_lstm)\n",
    "print(\"Accuracy: \",accuracy_max_s_lstm)\n",
    "\n",
    "print(\"### Stacked_LSTM Results : Min Score for all Sentence ###\")\n",
    "print(\"RMSE: \",rmse_min_s_lstm)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_min_s_lstm)\n",
    "print(\"Accuracy: \",accuracy_min_s_lstm)\n",
    "\n",
    "print(\"### Stacked_LSTM Results : Mean Score for all Sentence ###\")\n",
    "print(\"RMSE: \",rmse_mean_s_lstm)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_mean_s_lstm)\n",
    "print(\"Accuracy: \",accuracy_mean_s_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Mean Score is giving us best result, let us consider this as the main parameter \n",
    "# and calculate the per essay set scores\n",
    "\n",
    "def essay_set_metrics(df):\n",
    "    set_df = pd.DataFrame(columns=['essay_set','RMSE','Kappa','Accuracy'])\n",
    "    e_sets = np.unique(df.essay_set)\n",
    "    for e_s in e_sets:\n",
    "        df_s = df[df.essay_set == e_s]\n",
    "        original_score = df_s.Orig_Score.values.astype(int)\n",
    "        predicted_score = df_s.Mean_Score.values.astype(int)\n",
    "        rmse = RMSE(original_score,predicted_score)\n",
    "        kappa = cohen_kappa_score(original_score,predicted_score)\n",
    "        accuracy = accuracy_score(original_score,predicted_score)\n",
    "        set_df = set_df.append({'essay_set':e_s,'RMSE':rmse,'Kappa':kappa,'Accuracy':accuracy},\n",
    "                              ignore_index=True)\n",
    "    return set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.434505</td>\n",
       "      <td>0.082459</td>\n",
       "      <td>0.300578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.877058</td>\n",
       "      <td>0.124204</td>\n",
       "      <td>0.469780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.771269</td>\n",
       "      <td>0.112052</td>\n",
       "      <td>0.424437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.628014</td>\n",
       "      <td>0.410937</td>\n",
       "      <td>0.605598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.931051</td>\n",
       "      <td>0.121352</td>\n",
       "      <td>0.413598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.833238</td>\n",
       "      <td>0.130024</td>\n",
       "      <td>0.511429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.714671</td>\n",
       "      <td>-0.004672</td>\n",
       "      <td>0.084375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.140174</td>\n",
       "      <td>0.021376</td>\n",
       "      <td>0.069182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set      RMSE     Kappa  Accuracy\n",
       "0        1.0  1.434505  0.082459  0.300578\n",
       "1        2.0  0.877058  0.124204  0.469780\n",
       "2        3.0  0.771269  0.112052  0.424437\n",
       "3        4.0  0.628014  0.410937  0.605598\n",
       "4        5.0  0.931051  0.121352  0.413598\n",
       "5        6.0  0.833238  0.130024  0.511429\n",
       "6        7.0  4.714671 -0.004672  0.084375\n",
       "7        8.0  5.140174  0.021376  0.069182"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_set_results = essay_set_metrics(s_lstm_test_df)\n",
    "essay_set_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>sentence</th>\n",
       "      <th>orig_score</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, @CAPS1 people are talkin...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>People believe that using the computer is a wa...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>I believe that computers aren't a bad thing.</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>Using the computers can help us learn about ot...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>It can also show us the lives about people fro...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>We can also talk to our friends online.</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>If you want to know why computers are useful, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>People say that computers waste our lives.</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>I disagree with that opinion.</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>The internet is a great way to learn about dif...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id essay_set                                           sentence  \\\n",
       "0     1722         1  Dear local newspaper, @CAPS1 people are talkin...   \n",
       "1     1722         1  People believe that using the computer is a wa...   \n",
       "2     1722         1       I believe that computers aren't a bad thing.   \n",
       "3     1722         1  Using the computers can help us learn about ot...   \n",
       "4     1722         1  It can also show us the lives about people fro...   \n",
       "5     1722         1            We can also talk to our friends online.   \n",
       "6     1722         1  If you want to know why computers are useful, ...   \n",
       "7     1722         1         People say that computers waste our lives.   \n",
       "8     1722         1                      I disagree with that opinion.   \n",
       "9     1722         1  The internet is a great way to learn about dif...   \n",
       "\n",
       "  orig_score pred_score  \n",
       "0          9          9  \n",
       "1          9          9  \n",
       "2          9          9  \n",
       "3          9          8  \n",
       "4          9          9  \n",
       "5          9          8  \n",
       "6          9          8  \n",
       "7          9          9  \n",
       "8          9          9  \n",
       "9          9          9  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame([x_test_sentence_df.essay_id.values,x_test_sentence_df.essay_set.values,\n",
    "                         x_test_sentence_df.sentence.values,cnn_df.Orig_Score.values,\n",
    "                          cnn_df.Denorm_Pred_Score.values]).transpose()\n",
    "result_df.columns = ['essay_id','essay_set','sentence','orig_score','pred_score']\n",
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2596, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>Orig_Score</th>\n",
       "      <th>Max_Score</th>\n",
       "      <th>Min_Score</th>\n",
       "      <th>Mean_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  Orig_Score  Max_Score  Min_Score  Mean_Score\n",
       "0         2          1           9         10          7           9\n",
       "1         5          1           8         11          6           9\n",
       "2         9          1           9         10          7           9\n",
       "3        14          1           6          9          6           8\n",
       "4        25          1           8         10          8           9\n",
       "5        31          1          10         10          8           9\n",
       "6        33          1           6          9          7           8\n",
       "7        38          1           8         10          8           9\n",
       "8        39          1          10         10          7           8\n",
       "9        41          1           2          9          8           9"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_test_df = find_max_min_mean_score(result_df)\n",
    "cnn_test_df.essay_id = cnn_test_df.essay_id.astype(int)\n",
    "cnn_test_df.essay_set = cnn_test_df.essay_set.astype(int)\n",
    "cnn_test_df.Orig_Score = cnn_test_df.Orig_Score.astype(int)\n",
    "cnn_test_df.Max_Score = cnn_test_df.Max_Score.astype(int)\n",
    "cnn_test_df.Min_Score = cnn_test_df.Min_Score.astype(int)\n",
    "cnn_test_df.Mean_Score = cnn_test_df.Mean_Score.astype(int)\n",
    "\n",
    "print(cnn_test_df.shape)\n",
    "cnn_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### CNN_LSTM Results : MAX Score of all Sentences ###\n",
      "RMSE:  3.1274913027854225\n",
      "Cohen Kappa:  0.19453306187010388\n",
      "Accuracy:  0.2842835130970724\n",
      "### CNN_LSTM Results : Min Score of all Sentences ###\n",
      "RMSE:  3.4656580651219975\n",
      "Cohen Kappa:  0.211439054050241\n",
      "Accuracy:  0.31163328197226503\n",
      "### CNN_LSTM Results : Mean Score of all Sentences ###\n",
      "RMSE:  2.2545109719516185\n",
      "Cohen Kappa:  0.2981747205219023\n",
      "Accuracy:  0.3882896764252696\n"
     ]
    }
   ],
   "source": [
    "orig_score = cnn_test_df.Orig_Score.values\n",
    "max_pred_score = cnn_test_df.Max_Score.values\n",
    "min_pred_score = cnn_test_df.Min_Score.values\n",
    "mean_pred_score = cnn_test_df.Mean_Score.values\n",
    "\n",
    "rmse_max_cnn = RMSE(orig_score,max_pred_score)\n",
    "cohen_kappa_max_cnn = cohen_kappa_score(orig_score,max_pred_score)\n",
    "accuracy_max_cnn = accuracy_score(orig_score,max_pred_score)\n",
    "\n",
    "rmse_min_cnn = RMSE(orig_score,min_pred_score)\n",
    "cohen_kappa_min_cnn = cohen_kappa_score(orig_score,min_pred_score)\n",
    "accuracy_min_cnn = accuracy_score(orig_score,min_pred_score)\n",
    "\n",
    "rmse_mean_cnn = RMSE(orig_score,mean_pred_score)\n",
    "cohen_kappa_mean_cnn = cohen_kappa_score(orig_score,mean_pred_score)\n",
    "accuracy_mean_cnn = accuracy_score(orig_score,mean_pred_score)\n",
    "\n",
    "print(\"### CNN_LSTM Results : MAX Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_max_cnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_max_cnn)\n",
    "print(\"Accuracy: \",accuracy_max_cnn)\n",
    "\n",
    "print(\"### CNN_LSTM Results : Min Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_min_cnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_min_cnn)\n",
    "print(\"Accuracy: \",accuracy_min_cnn)\n",
    "\n",
    "print(\"### CNN_LSTM Results : Mean Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_mean_cnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_mean_cnn)\n",
    "print(\"Accuracy: \",accuracy_mean_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.434505</td>\n",
       "      <td>0.082459</td>\n",
       "      <td>0.300578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.877058</td>\n",
       "      <td>0.124204</td>\n",
       "      <td>0.469780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.771269</td>\n",
       "      <td>0.112052</td>\n",
       "      <td>0.424437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.628014</td>\n",
       "      <td>0.410937</td>\n",
       "      <td>0.605598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.931051</td>\n",
       "      <td>0.121352</td>\n",
       "      <td>0.413598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.833238</td>\n",
       "      <td>0.130024</td>\n",
       "      <td>0.511429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.714671</td>\n",
       "      <td>-0.004672</td>\n",
       "      <td>0.084375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.140174</td>\n",
       "      <td>0.021376</td>\n",
       "      <td>0.069182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set      RMSE     Kappa  Accuracy\n",
       "0        1.0  1.434505  0.082459  0.300578\n",
       "1        2.0  0.877058  0.124204  0.469780\n",
       "2        3.0  0.771269  0.112052  0.424437\n",
       "3        4.0  0.628014  0.410937  0.605598\n",
       "4        5.0  0.931051  0.121352  0.413598\n",
       "5        6.0  0.833238  0.130024  0.511429\n",
       "6        7.0  4.714671 -0.004672  0.084375\n",
       "7        8.0  5.140174  0.021376  0.069182"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_set_results = essay_set_metrics(cnn_test_df)\n",
    "essay_set_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
