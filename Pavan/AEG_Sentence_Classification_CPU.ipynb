{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import json, os, re, shutil, sys, time\n",
    "import seaborn as sns\n",
    "from importlib import reload\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "from collections import defaultdict\n",
    "import xmltodict\n",
    "import untangle\n",
    "import xml.etree.ElementTree as ET\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Import spacy\n",
    "import spacy\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NumPy, Pandas and TensorFlow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import CONTRACTION_MAP\n",
    "import unicodedata\n",
    "\n",
    "from numpy.random import seed\n",
    "from pandas import read_csv, DataFrame\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Activation, Dropout, Conv1D, MaxPooling1D, Bidirectional, Flatten, TimeDistributed\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import keras.backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEG Long Essay Sentence Level Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score      ...        \\\n",
       "0             NaN             NaN            NaN      ...         \n",
       "1             NaN             NaN            NaN      ...         \n",
       "2             NaN             NaN            NaN      ...         \n",
       "3             NaN             NaN            NaN      ...         \n",
       "4             NaN             NaN            NaN      ...         \n",
       "\n",
       "   rater2_trait3  rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "aeg_long = pd.read_csv(\"../data-DNC/AEG/training_set_rel3.tsv\",sep='\\t',encoding = \"latin1\")\n",
    "aeg_long.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test. We need to do this first to ensure that when we split to \n",
    "# sentence level, we have sentences of a given essay in either training or test but not on both.\n",
    "\n",
    "tr_essay,ts_essay,tr_domain_score,ts_domain_score,tr_essay_id,ts_essay_id,tr_essay_set,ts_essay_set=train_test_split(\n",
    "    np.asarray(aeg_long.essay),np.asarray(aeg_long.domain1_score),\n",
    "    np.asarray(aeg_long.essay_id),np.asarray(aeg_long.essay_set),test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10380,)\n",
      "(2596,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of training and test datasets\n",
    "print(tr_essay.shape)\n",
    "print(ts_essay.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test data frames with relevant fields\n",
    "\n",
    "x_train_df = pd.DataFrame([tr_essay_id,tr_essay_set,tr_essay,tr_domain_score.astype(np.double)]).transpose()\n",
    "x_train_df.columns = ['essay_id','essay_set','essay','domain1_score']\n",
    "x_test_df = pd.DataFrame([ts_essay_id,ts_essay_set,ts_essay,ts_domain_score.astype(np.double)]).transpose()\n",
    "x_test_df.columns = ['essay_id','essay_set','essay','domain1_score']\n",
    "#print(x_train_df.head(5))\n",
    "#print(x_test_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split essay into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use spacy to split the essay into sentences. \n",
    "# Load spacy large english module\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to split essay into sentences\n",
    "def create_sentences_df(df):\n",
    "    \"\"\" Function to split essay data into individual sentences. Returns a dataframe\"\"\"\n",
    "    start=datetime.now()\n",
    "    aeg_long_sentence = pd.DataFrame(columns=['essay_id','essay_set','sentence','domain1_score'])\n",
    "    for i in range(len(df)):\n",
    "        if i%1000 == 0:\n",
    "            print(\"At iteration :\",i)\n",
    "            print(\"Duration: \",datetime.now()-start)\n",
    "        sentence = nlp(df.essay[i])\n",
    "        for s in sentence.sents:\n",
    "            aeg_long_sentence = aeg_long_sentence.append({'essay_id' : df.essay_id[i],\n",
    "                                                          'essay_set' : df.essay_set[i],'sentence' : s.text, \n",
    "                                                          'domain1_score' : df.domain1_score[i]},\n",
    "                                                         ignore_index=True)\n",
    "    return aeg_long_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We also need to convert the spacy format text into regular text\n",
    "def spacy_to_text(essay):\n",
    "    return essay[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration : 0\n",
      "Duration:  0:00:00.001094\n",
      "At iteration : 1000\n",
      "Duration:  0:01:13.910230\n",
      "At iteration : 2000\n",
      "Duration:  0:02:41.471731\n",
      "At iteration : 3000\n",
      "Duration:  0:04:57.690647\n",
      "At iteration : 4000\n",
      "Duration:  0:07:51.580886\n",
      "At iteration : 5000\n",
      "Duration:  0:11:39.480142\n",
      "At iteration : 6000\n",
      "Duration:  0:16:11.116163\n",
      "At iteration : 7000\n",
      "Duration:  0:21:46.361166\n",
      "At iteration : 8000\n",
      "Duration:  0:27:57.529110\n",
      "At iteration : 9000\n",
      "Duration:  0:34:42.670452\n",
      "At iteration : 10000\n",
      "Duration:  0:42:12.653912\n"
     ]
    }
   ],
   "source": [
    "# Split train data into sentences\n",
    "x_train_sentence_df = create_sentences_df(x_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration : 0\n",
      "Duration:  0:00:00.001098\n",
      "At iteration : 1000\n",
      "Duration:  0:01:15.384433\n",
      "At iteration : 2000\n",
      "Duration:  0:02:53.557499\n"
     ]
    }
   ],
   "source": [
    "# Split test data into sentences\n",
    "x_test_sentence_df = create_sentences_df(x_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each essay set has a different scoring range. We need to normalize the scores to a standard scale for training.\n",
    "def normalize_score(essay):\n",
    "    \"\"\" Normalizes the domain score based on percentage\"\"\"\n",
    "    score = 0\n",
    "    score = float(essay[3])\n",
    "    essay_set = essay[1]\n",
    "    if essay_set == 1:\n",
    "        div = 12\n",
    "    elif essay_set == 2:\n",
    "        div = 5\n",
    "    elif essay_set == 3:\n",
    "        div = 3\n",
    "    elif essay_set == 4:\n",
    "        div = 3\n",
    "    elif essay_set == 5:\n",
    "        div = 4\n",
    "    elif essay_set == 6:\n",
    "        div = 4\n",
    "    elif essay_set == 7:\n",
    "        div = 25\n",
    "    elif essay_set == 8:\n",
    "        div = 50\n",
    "    return score/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_sentence_df['Norm_Score'] = x_train_sentence_df.apply(normalize_score,axis=1)\n",
    "x_test_sentence_df['Norm_Score'] = x_test_sentence_df.apply(normalize_score,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>sentence</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>Norm_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4075</td>\n",
       "      <td>2</td>\n",
       "      <td>Did your child ever bring home a book?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4075</td>\n",
       "      <td>2</td>\n",
       "      <td>A piece of music, movie or magazine?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4075</td>\n",
       "      <td>2</td>\n",
       "      <td>Did you ever stop to think that the piece of i...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4075</td>\n",
       "      <td>2</td>\n",
       "      <td>There are points in time where there isn't an ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4075</td>\n",
       "      <td>2</td>\n",
       "      <td>The driving question is do you want to remove ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id essay_set                                           sentence  \\\n",
       "0     4075         2             Did your child ever bring home a book?   \n",
       "1     4075         2               A piece of music, movie or magazine?   \n",
       "2     4075         2  Did you ever stop to think that the piece of i...   \n",
       "3     4075         2  There are points in time where there isn't an ...   \n",
       "4     4075         2  The driving question is do you want to remove ...   \n",
       "\n",
       "   domain1_score  Norm_Score  \n",
       "0            3.0         0.6  \n",
       "1            3.0         0.6  \n",
       "2            3.0         0.6  \n",
       "3            3.0         0.6  \n",
       "4            3.0         0.6  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sentence_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store this dataset in pickle format so that we don't have to redo the above steps.\n",
    "x_train_sentence_df.to_pickle(\"./x_train_sentence_df.pkl\")\n",
    "x_test_sentence_df.to_pickle(\"./x_test_sentence_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147647,)\n",
      "(147647,)\n",
      "(36254,)\n",
      "(36254,)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test text and labels\n",
    "\n",
    "x_train = x_train_sentence_df['sentence'].values\n",
    "y_train = x_train_sentence_df['Norm_Score'].values\n",
    "x_test = x_test_sentence_df['sentence'].values\n",
    "y_test = x_test_sentence_df['Norm_Score'].values\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "train_data = pad_sequences(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len_class = train_data.shape[1]\n",
    "max_words_class = vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36254, 175)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "test_data = pad_sequences(test_seq, maxlen=max_len_class)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1917494 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('/Users/kurapati/W266/data/glove.42B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocabulary_size, 300))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(actual, predict):\n",
    "    diff = actual - predict\n",
    "    diff = sum(diff**2) / len(actual)\n",
    "    return np.sqrt(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cohen Kappa score as defined by the kaggle challenge/wikipedia\n",
    "def CohenKappa(actual, predict):\n",
    "    CohenDF = pd.DataFrame([actual.astype(np.double).round(), np.around(predict.astype(np.double))]).transpose()\n",
    "    count = len(CohenDF)\n",
    "    CohenDF.columns = ['actual','predict']\n",
    "    correct = len(CohenDF[CohenDF.actual==CohenDF.predict])\n",
    "    acc = correct / count\n",
    "    pe = 0\n",
    "    for value in CohenDF.actual.unique():\n",
    "        pe += len(CohenDF[CohenDF.actual == value]) * len(CohenDF[CohenDF.predict == value])\n",
    "    pe = pe / np.square(count)\n",
    "    print(\"Count: \",count)\n",
    "    print(\"pe:\" ,pe)\n",
    "    return(1 - (1-acc)/(1-pe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skll.metrics as metric\n",
    "\n",
    "# Calculates the average quadratic kappa for the entire essay set\n",
    "def get_average_kappa(targets, predictions):\n",
    "        num = len(targets)\n",
    "        total_kappa = 0\n",
    "\n",
    "        for i in range(0, num):\n",
    "                total_kappa += metric.kappa([targets], [predictions], 'quadratic')\n",
    "\n",
    "        avg_kappa  = float(total_kappa) / float(num)\n",
    "        return avg_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_all = TfidfVectorizer()\n",
    "tfidf_all.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_transform = tfidf_all.transform(x_train)\n",
    "test_transform = tfidf_all.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gnb = GaussianNB()\n",
    "#lr = LinearRegression(fit_intercept=True)\n",
    "#rf = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gnb.fit(train_transform.toarray(), train_y_sentence)\n",
    "#lr.fit(train_transform.toarray(), train_y_sentence)\n",
    "#rf.fit(train_transform.toarray(), train_y_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147647, 33809)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len_class = train_data.shape[1]\n",
    "max_words_class = vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model definitions\n",
    "\n",
    "def CNN_lstm():\n",
    "    \"\"\" CNN with single layer LSTM\"\"\"\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], trainable=False))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_conv.add(tf.keras.layers.Conv1D(64, 5, activation='relu'))\n",
    "    model_conv.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "    model_conv.add(tf.keras.layers.LSTM(100))\n",
    "    model_conv.add(tf.keras.layers.Dense(100))\n",
    "    model_conv.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    #sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "    model_conv.compile(loss = 'mse', optimizer = tf.train.AdamOptimizer(), metrics = ['accuracy'])\n",
    "    #model_conv.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "def stack_lstm():\n",
    "    \"\"\" Stacked LSTM\"\"\"\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], trainable=False))\n",
    "    #model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    #model_conv.add(tf.keras.layers.Conv1D(64, 5, activation='relu'))\n",
    "    #model_conv.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "    #model_conv.add(tf.keras.layers.Dropout(0.2))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32,return_sequences=True))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32, return_sequences=True))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.2))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32))\n",
    "    model_conv.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    #sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "    model_conv.compile(loss = 'mse', optimizer = tf.train.AdamOptimizer(), metrics = ['accuracy'])\n",
    "    #model_conv.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "def stateful_stacked_lstm():\n",
    "    # In stateful, total samples needs to be divisible by batch size\n",
    "    # we have 147026 samples, so selecting 6683 (6683*22=147026)\n",
    "    batch_size=6683\n",
    "    model_conv = Sequential()\n",
    "    # In stateful, we have to pass batch_input_shape to the first layer\n",
    "    model_conv.add(tf.keras.layers.Embedding(max_words_class, 300, input_length=max_len_class, weights=[embedding_matrix], \n",
    "                                             trainable=False,batch_input_shape=(batch_size,max_len_class)))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32,stateful=True,return_sequences=True))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_conv.add(tf.keras.layers.LSTM(32))\n",
    "    model_conv.add(tf.keras.layers.Dropout(0.1))\n",
    "    model_conv.add(tf.keras.layers.Dense(100))\n",
    "    model_conv.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    #sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "    model_conv.compile(loss = 'mse', optimizer = tf.train.AdamOptimizer(), metrics = ['accuracy'])\n",
    "    #model_conv.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "#bidirectional RNN is screwed up atm\n",
    "def Bidirectional_RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len_class])\n",
    "    layer = Embedding(max_words,200,input_length=max_len_class)(inputs)\n",
    "    layer = Bidirectional(LSTM(10))(layer)\n",
    "    layer = Dense(32,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n",
    "\n",
    "def feedforward_NN():\n",
    "    model_ff = Sequential()\n",
    "    model_ff.add(tf.keras.layers.Embedding(max_words_class,200,input_length=max_len_class))\n",
    "    model_ff.add(tf.keras.layers.Flatten())\n",
    "    model_ff.add(tf.keras.layers.Dense(50,activation='tanh'))\n",
    "    model_ff.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "    model_ff.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_ff\n",
    "\n",
    "def RNN():\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(tf.keras.layers.Embedding(max_words_class,300,input_length=max_len_class))\n",
    "    model_rnn.add(tf.keras.layers.LSTM(10))\n",
    "    model_rnn.add(tf.keras.layers.Dense(1,name='out_layer'))\n",
    "    model_rnn.compile(optimizer=tf.train.AdamOptimizer(),loss='mse',metrics=['accuracy'])\n",
    "    return model_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(build_fn=CNN_glove_1, epochs=20, batch_size=500)\n",
    "#kfold = KFold(n_splits=5, random_state=43)\n",
    "#results = np.sqrt(-1*cross_val_score(estimator, train_data, train_y_sentence,scoring= \"neg_mean_squared_error\", cv=kfold))\n",
    "#print(\"Training RMSE mean and std from CV: {} {}\".format(results.mean(),results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "147647/147647 [==============================] - 231s 2ms/step - loss: 0.1394 - acc: 0.0926\n",
      "Epoch 2/20\n",
      "147647/147647 [==============================] - 230s 2ms/step - loss: 0.0309 - acc: 0.0998\n",
      "Epoch 3/20\n",
      "147647/147647 [==============================] - 228s 2ms/step - loss: 0.0298 - acc: 0.0999\n",
      "Epoch 4/20\n",
      "147647/147647 [==============================] - 226s 2ms/step - loss: 0.0292 - acc: 0.1001\n",
      "Epoch 5/20\n",
      "147647/147647 [==============================] - 227s 2ms/step - loss: 0.0287 - acc: 0.1002\n",
      "Epoch 6/20\n",
      "147647/147647 [==============================] - 549s 4ms/step - loss: 0.0283 - acc: 0.1004\n",
      "Epoch 7/20\n",
      "147647/147647 [==============================] - 246s 2ms/step - loss: 0.0280 - acc: 0.1006\n",
      "Epoch 8/20\n",
      "147647/147647 [==============================] - 236s 2ms/step - loss: 0.0277 - acc: 0.1008\n",
      "Epoch 9/20\n",
      "147647/147647 [==============================] - 238s 2ms/step - loss: 0.0275 - acc: 0.1008\n",
      "Epoch 10/20\n",
      "147647/147647 [==============================] - 250s 2ms/step - loss: 0.0272 - acc: 0.1011\n",
      "Epoch 11/20\n",
      "147647/147647 [==============================] - 240s 2ms/step - loss: 0.0268 - acc: 0.1014\n",
      "Epoch 12/20\n",
      "147647/147647 [==============================] - 254s 2ms/step - loss: 0.0267 - acc: 0.1016\n",
      "Epoch 13/20\n",
      "147647/147647 [==============================] - 268s 2ms/step - loss: 0.0264 - acc: 0.1016\n",
      "Epoch 14/20\n",
      "147647/147647 [==============================] - 246s 2ms/step - loss: 0.0262 - acc: 0.1018\n",
      "Epoch 15/20\n",
      "147647/147647 [==============================] - 235s 2ms/step - loss: 0.0259 - acc: 0.1019\n",
      "Epoch 16/20\n",
      "147647/147647 [==============================] - 230s 2ms/step - loss: 0.0255 - acc: 0.1020\n",
      "Epoch 17/20\n",
      "147647/147647 [==============================] - 231s 2ms/step - loss: 0.0254 - acc: 0.1021\n",
      "Epoch 18/20\n",
      "147647/147647 [==============================] - 231s 2ms/step - loss: 0.0252 - acc: 0.1023\n",
      "Epoch 19/20\n",
      "147647/147647 [==============================] - 230s 2ms/step - loss: 0.0248 - acc: 0.1025\n",
      "Epoch 20/20\n",
      "147647/147647 [==============================] - 233s 2ms/step - loss: 0.0247 - acc: 0.1025\n",
      "RMSE:  0.16874617569397307\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(train_data, y_train)\n",
    "prediction_cnn_glove=estimator.predict(test_data)\n",
    "rmse_val = RMSE(y_test,prediction_cnn_glove)\n",
    "print(\"RMSE: \",rmse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get the multiplication factor. We can get it back from the essay set, but\n",
    "# it is better to do it from the score, because there are scores with value 0, and its MF should be 0\n",
    "\n",
    "def find_mult_factor(x):\n",
    "    \"\"\" Function to find the multiplication factor for denormalizing\"\"\"\n",
    "    if x[1] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.around(x[0]/x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig_Score</th>\n",
       "      <th>Norm_Score</th>\n",
       "      <th>Pred_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.778362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.766187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.675432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.782038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.739532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.722847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.726954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.709436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.801359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Orig_Score  Norm_Score  Pred_Score\n",
       "0         4.0         0.8    0.778362\n",
       "1         4.0         0.8    0.766187\n",
       "2         4.0         0.8    0.675432\n",
       "3         4.0         0.8    0.782038\n",
       "4         4.0         0.8    0.754179\n",
       "5         4.0         0.8    0.739532\n",
       "6         4.0         0.8    0.722847\n",
       "7         4.0         0.8    0.726954\n",
       "8         4.0         0.8    0.709436\n",
       "9         4.0         0.8    0.801359"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df = pd.DataFrame([x_test_sentence_df['domain1_score'].astype(np.double), y_test.astype(np.double),\n",
    "                      prediction_cnn_glove.astype(np.double)]).transpose()\n",
    "cnn_df.columns = ['Orig_Score','Norm_Score','Pred_Score']\n",
    "cnn_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig_Score</th>\n",
       "      <th>Norm_Score</th>\n",
       "      <th>Pred_Score</th>\n",
       "      <th>Mult_Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.778362</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.766187</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.675432</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.782038</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.754179</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.739532</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.722847</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.726954</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.709436</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.801359</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Orig_Score  Norm_Score  Pred_Score  Mult_Factor\n",
       "0         4.0         0.8    0.778362          5.0\n",
       "1         4.0         0.8    0.766187          5.0\n",
       "2         4.0         0.8    0.675432          5.0\n",
       "3         4.0         0.8    0.782038          5.0\n",
       "4         4.0         0.8    0.754179          5.0\n",
       "5         4.0         0.8    0.739532          5.0\n",
       "6         4.0         0.8    0.722847          5.0\n",
       "7         4.0         0.8    0.726954          5.0\n",
       "8         4.0         0.8    0.709436          5.0\n",
       "9         4.0         0.8    0.801359          5.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df['Mult_Factor'] = cnn_df.apply(find_mult_factor,axis=1)\n",
    "cnn_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig_Score</th>\n",
       "      <th>Norm_Score</th>\n",
       "      <th>Pred_Score</th>\n",
       "      <th>Mult_Factor</th>\n",
       "      <th>Denorm_Pred_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.778362</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.766187</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.675432</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.782038</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.754179</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.739532</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.722847</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.726954</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.709436</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.801359</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Orig_Score  Norm_Score  Pred_Score  Mult_Factor  Denorm_Pred_Score\n",
       "0         4.0         0.8    0.778362          5.0                4.0\n",
       "1         4.0         0.8    0.766187          5.0                4.0\n",
       "2         4.0         0.8    0.675432          5.0                3.0\n",
       "3         4.0         0.8    0.782038          5.0                4.0\n",
       "4         4.0         0.8    0.754179          5.0                4.0\n",
       "5         4.0         0.8    0.739532          5.0                4.0\n",
       "6         4.0         0.8    0.722847          5.0                4.0\n",
       "7         4.0         0.8    0.726954          5.0                4.0\n",
       "8         4.0         0.8    0.709436          5.0                4.0\n",
       "9         4.0         0.8    0.801359          5.0                4.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def denormalize(x):\n",
    "    return np.around(x[2] * x[3])\n",
    "cnn_df['Denorm_Pred_Score'] = cnn_df.apply(denormalize,axis=1)\n",
    "cnn_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36254, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.6334048274563844\n"
     ]
    }
   ],
   "source": [
    "orig_score = cnn_df.Orig_Score.as_matrix(columns=None)\n",
    "orig_score = orig_score.astype(np.int)\n",
    "pred_score = cnn_df.Denorm_Pred_Score.as_matrix(columns=None)\n",
    "pred_score = pred_score.astype(np.int)\n",
    "rmse_cnn = RMSE(orig_score,pred_score)\n",
    "print(\"RMSE: \",rmse_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen Kappa:  0.2625413498538345\n"
     ]
    }
   ],
   "source": [
    "cohen_kappa = cohen_kappa_score(orig_score,pred_score)\n",
    "print(\"Cohen Kappa: \",cohen_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.3285430573178132\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(orig_score,pred_score)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating per essay score based on sentence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>sentence</th>\n",
       "      <th>orig_score</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>'All of us can think of a book that we hope no...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>But if I have the right to remove that book fr...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>and so does everyone else.</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>And then we have no books left on the shelf fo...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>wrote by Katherine Paterson.</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>If you think about it when you go into a libra...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>But how many do you think is appropiate for ev...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>That is why they have sections for the books, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>How many times have you been in a library and ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>Many of times right, that can be accidental or...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>I know if I took my child or children to a lib...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>Now if it was a book that has been misplaced I...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>But, yes there are some books, magazines, movi...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>I remember from when I was a little girl going...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>They were pleased that I loved to read but, on...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>and she realized on of my books had a cursing ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>She was not happy at all, I had no clue what s...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>But I figured it out, she grabbed me by my han...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>She fastened me in and off we went, back to th...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>She had no problem going off and complaining, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>@CAPS1, my name is @LOCATION2 and this is my d...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>she is six years old.</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>We were just her about an hour ago, but you wa...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>Well if you can give me a funny reason for why...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>Please speak up and explain I would love to he...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>The lady at the front desk was stunned she has...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>But the book is no longer in the @LOCATION1 li...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>Just like Katherine Paterson said, 'All of us ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>But if I have the right to remove that book fr...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>I abhor- then you also have exactly the same r...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>And then we have no books left on the shelf fo...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>I can tell you from experience and observation...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4479</td>\n",
       "      <td>2</td>\n",
       "      <td>It @MONTH1 cause trouble but just set your min...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear people, Computers have been here for not ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>As they are used for entertainment, education,...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>Let me explain.</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>First of all, as people use computers in the b...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>They go on the @CAPS1, play games, and use it ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>But as they keep using it, they start to get a...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>People are addicted to computers because of th...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>In fact, @PERCENT1 of all the people in this @...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>That percentage is expected to grow to @PERCEN...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>Addiction to computers lead to serious issues.</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>People have died because they spent too much t...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>In another newspaper not long ago, it stated t...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>His parent found out that he was addicted to t...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>\" This game is right now the most played game ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>Studies state that @CAPS8 addiction is almost ...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>My second reason why @CAPS8 has a negative eff...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>People chat on @CAPS5, @CAPS6, @CAPS7, and ema...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id essay_set                                           sentence  \\\n",
       "0      4479         2  'All of us can think of a book that we hope no...   \n",
       "1      4479         2  But if I have the right to remove that book fr...   \n",
       "2      4479         2                         and so does everyone else.   \n",
       "3      4479         2  And then we have no books left on the shelf fo...   \n",
       "4      4479         2                       wrote by Katherine Paterson.   \n",
       "5      4479         2  If you think about it when you go into a libra...   \n",
       "6      4479         2  But how many do you think is appropiate for ev...   \n",
       "7      4479         2  That is why they have sections for the books, ...   \n",
       "8      4479         2  How many times have you been in a library and ...   \n",
       "9      4479         2  Many of times right, that can be accidental or...   \n",
       "10     4479         2  I know if I took my child or children to a lib...   \n",
       "11     4479         2  Now if it was a book that has been misplaced I...   \n",
       "12     4479         2  But, yes there are some books, magazines, movi...   \n",
       "13     4479         2  I remember from when I was a little girl going...   \n",
       "14     4479         2  They were pleased that I loved to read but, on...   \n",
       "15     4479         2  and she realized on of my books had a cursing ...   \n",
       "16     4479         2  She was not happy at all, I had no clue what s...   \n",
       "17     4479         2  But I figured it out, she grabbed me by my han...   \n",
       "18     4479         2  She fastened me in and off we went, back to th...   \n",
       "19     4479         2  She had no problem going off and complaining, ...   \n",
       "20     4479         2  @CAPS1, my name is @LOCATION2 and this is my d...   \n",
       "21     4479         2                              she is six years old.   \n",
       "22     4479         2  We were just her about an hour ago, but you wa...   \n",
       "23     4479         2  Well if you can give me a funny reason for why...   \n",
       "24     4479         2  Please speak up and explain I would love to he...   \n",
       "25     4479         2  The lady at the front desk was stunned she has...   \n",
       "26     4479         2  But the book is no longer in the @LOCATION1 li...   \n",
       "27     4479         2  Just like Katherine Paterson said, 'All of us ...   \n",
       "28     4479         2  But if I have the right to remove that book fr...   \n",
       "29     4479         2  I abhor- then you also have exactly the same r...   \n",
       "30     4479         2  And then we have no books left on the shelf fo...   \n",
       "31     4479         2  I can tell you from experience and observation...   \n",
       "32     4479         2  It @MONTH1 cause trouble but just set your min...   \n",
       "33     1175         1  Dear people, Computers have been here for not ...   \n",
       "34     1175         1  As they are used for entertainment, education,...   \n",
       "35     1175         1                                    Let me explain.   \n",
       "36     1175         1  First of all, as people use computers in the b...   \n",
       "37     1175         1  They go on the @CAPS1, play games, and use it ...   \n",
       "38     1175         1  But as they keep using it, they start to get a...   \n",
       "39     1175         1  People are addicted to computers because of th...   \n",
       "40     1175         1  In fact, @PERCENT1 of all the people in this @...   \n",
       "41     1175         1  That percentage is expected to grow to @PERCEN...   \n",
       "42     1175         1     Addiction to computers lead to serious issues.   \n",
       "43     1175         1  People have died because they spent too much t...   \n",
       "44     1175         1  In another newspaper not long ago, it stated t...   \n",
       "45     1175         1  His parent found out that he was addicted to t...   \n",
       "46     1175         1  \" This game is right now the most played game ...   \n",
       "47     1175         1  Studies state that @CAPS8 addiction is almost ...   \n",
       "48     1175         1  My second reason why @CAPS8 has a negative eff...   \n",
       "49     1175         1  People chat on @CAPS5, @CAPS6, @CAPS7, and ema...   \n",
       "\n",
       "   orig_score pred_score  \n",
       "0           4          4  \n",
       "1           4          4  \n",
       "2           4          3  \n",
       "3           4          4  \n",
       "4           4          4  \n",
       "5           4          4  \n",
       "6           4          4  \n",
       "7           4          4  \n",
       "8           4          4  \n",
       "9           4          4  \n",
       "10          4          4  \n",
       "11          4          4  \n",
       "12          4          4  \n",
       "13          4          4  \n",
       "14          4          4  \n",
       "15          4          4  \n",
       "16          4          4  \n",
       "17          4          4  \n",
       "18          4          4  \n",
       "19          4          4  \n",
       "20          4          4  \n",
       "21          4          3  \n",
       "22          4          3  \n",
       "23          4          3  \n",
       "24          4          4  \n",
       "25          4          4  \n",
       "26          4          3  \n",
       "27          4          4  \n",
       "28          4          4  \n",
       "29          4          4  \n",
       "30          4          4  \n",
       "31          4          3  \n",
       "32          4          4  \n",
       "33          9          9  \n",
       "34          9          9  \n",
       "35          9          9  \n",
       "36          9          9  \n",
       "37          9          9  \n",
       "38          9          8  \n",
       "39          9          9  \n",
       "40          9          9  \n",
       "41          9          9  \n",
       "42          9         10  \n",
       "43          9          9  \n",
       "44          9          9  \n",
       "45          9          8  \n",
       "46          9          9  \n",
       "47          9         11  \n",
       "48          9          9  \n",
       "49          9          9  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame([x_test_sentence_df.essay_id.values,x_test_sentence_df.essay_set.values,\n",
    "                         x_test_sentence_df.sentence.values,cnn_df.Orig_Score.values,\n",
    "                          cnn_df.Denorm_Pred_Score.values]).transpose()\n",
    "result_df.columns = ['essay_id','essay_set','sentence','orig_score','pred_score']\n",
    "result_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_min_mean_score(df):\n",
    "    new_df = pd.DataFrame(columns=['essay_id','essay_set','Orig_Score','Max_Score','Min_Score','Mean_Score'])\n",
    "    essay_ids = np.unique(df.essay_id)\n",
    "    for e_id in essay_ids:\n",
    "        df_temp = df[df.essay_id == e_id]\n",
    "        max_score = np.max(df_temp.pred_score)\n",
    "        min_score = np.min(df_temp.pred_score)\n",
    "        # we need to round the mean so that kappa score doesnt complain\n",
    "        mean_score = np.around(np.mean(df_temp.pred_score))\n",
    "        new_df = new_df.append({'essay_id':e_id,'essay_set':int(np.unique(df_temp.essay_set)),\n",
    "                                'Orig_Score':int(np.unique(df_temp.orig_score)),'Max_Score':max_score,\n",
    "                                'Min_Score':min_score,'Mean_Score':mean_score},ignore_index=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2596, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>Orig_Score</th>\n",
       "      <th>Max_Score</th>\n",
       "      <th>Min_Score</th>\n",
       "      <th>Mean_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  Orig_Score  Max_Score  Min_Score  Mean_Score\n",
       "0         2          1           9         10          7           9\n",
       "1         4          1          10         10          8           9\n",
       "2         5          1           8         11          8           9\n",
       "3         9          1           9         11          8           9\n",
       "4        16          1          12         10          8           9\n",
       "5        18          1           8         10          7           9\n",
       "6        30          1           8         10          8           9\n",
       "7        72          1          10         11          9          10\n",
       "8        74          1           7         10          8           9\n",
       "9        77          1          10         11          8           9"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_test_df = find_max_min_mean_score(result_df)\n",
    "cnn_test_df.essay_id = cnn_test_df.essay_id.astype(int)\n",
    "cnn_test_df.essay_set = cnn_test_df.essay_set.astype(int)\n",
    "cnn_test_df.Orig_Score = cnn_test_df.Orig_Score.astype(int)\n",
    "cnn_test_df.Max_Score = cnn_test_df.Max_Score.astype(int)\n",
    "cnn_test_df.Min_Score = cnn_test_df.Min_Score.astype(int)\n",
    "cnn_test_df.Mean_Score = cnn_test_df.Mean_Score.astype(int)\n",
    "\n",
    "print(cnn_test_df.shape)\n",
    "cnn_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### CNN_LSTM Results : MAX Score of all Sentences ###\n",
      "RMSE:  2.986551778460191\n",
      "Cohen Kappa:  0.20126766063038737\n",
      "Accuracy:  0.2942989214175655\n",
      "### CNN_LSTM Results : Min Score of all Sentences ###\n",
      "RMSE:  2.6227198623027017\n",
      "Cohen Kappa:  0.2627931565262216\n",
      "Accuracy:  0.3640215716486903\n",
      "### CNN_LSTM Results : Mean Score of all Sentences ###\n",
      "RMSE:  2.1025335073336424\n",
      "Cohen Kappa:  0.270506422257236\n",
      "Accuracy:  0.3647919876733436\n"
     ]
    }
   ],
   "source": [
    "orig_score = cnn_test_df.Orig_Score.values\n",
    "max_pred_score = cnn_test_df.Max_Score.values\n",
    "min_pred_score = cnn_test_df.Min_Score.values\n",
    "mean_pred_score = cnn_test_df.Mean_Score.values\n",
    "\n",
    "rmse_max_cnn = RMSE(orig_score,max_pred_score)\n",
    "cohen_kappa_max_cnn = cohen_kappa_score(orig_score,max_pred_score)\n",
    "accuracy_max_cnn = accuracy_score(orig_score,max_pred_score)\n",
    "\n",
    "rmse_min_cnn = RMSE(orig_score,min_pred_score)\n",
    "cohen_kappa_min_cnn = cohen_kappa_score(orig_score,min_pred_score)\n",
    "accuracy_min_cnn = accuracy_score(orig_score,min_pred_score)\n",
    "\n",
    "rmse_mean_cnn = RMSE(orig_score,mean_pred_score)\n",
    "cohen_kappa_mean_cnn = cohen_kappa_score(orig_score,mean_pred_score)\n",
    "accuracy_mean_cnn = accuracy_score(orig_score,mean_pred_score)\n",
    "\n",
    "print(\"### CNN_LSTM Results : MAX Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_max_cnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_max_cnn)\n",
    "print(\"Accuracy: \",accuracy_max_cnn)\n",
    "\n",
    "print(\"### CNN_LSTM Results : Min Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_min_cnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_min_cnn)\n",
    "print(\"Accuracy: \",accuracy_min_cnn)\n",
    "\n",
    "print(\"### CNN_LSTM Results : Mean Score of all Sentences ###\")\n",
    "print(\"RMSE: \",rmse_mean_cnn)\n",
    "print(\"Cohen Kappa: \",cohen_kappa_mean_cnn)\n",
    "print(\"Accuracy: \",accuracy_mean_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Mean Score is giving us best result, let us consider this as the main parameter \n",
    "# and calculate the per essay set scores\n",
    "\n",
    "def essay_set_metrics(df):\n",
    "    set_df = pd.DataFrame(columns=['essay_set','RMSE','Kappa','Accuracy'])\n",
    "    e_sets = np.unique(df.essay_set)\n",
    "    for e_s in e_sets:\n",
    "        df_s = df[df.essay_set == e_s]\n",
    "        original_score = df_s.Orig_Score.values.astype(int)\n",
    "        predicted_score = df_s.Mean_Score.values.astype(int)\n",
    "        rmse = RMSE(original_score,predicted_score)\n",
    "        kappa = CohenKappa(original_score,predicted_score)\n",
    "        accuracy = accuracy_score(original_score,predicted_score)\n",
    "        set_df = set_df.append({'essay_set':e_s,'RMSE':rmse,'Kappa':kappa,'Accuracy':accuracy},\n",
    "                              ignore_index=True)\n",
    "    return set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  366\n",
      "pe: 0.2119501926005554\n",
      "Count:  365\n",
      "pe: 0.43579658472508914\n",
      "Count:  341\n",
      "pe: 0.391087107954008\n",
      "Count:  350\n",
      "pe: 0.31678367346938774\n",
      "Count:  375\n",
      "pe: 0.2891448888888889\n",
      "Count:  371\n",
      "pe: 0.43628715281057245\n",
      "Count:  285\n",
      "pe: 0.0718990458602647\n",
      "Count:  143\n",
      "pe: 0.04552789867475182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.435308</td>\n",
       "      <td>0.053484</td>\n",
       "      <td>0.254098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.889821</td>\n",
       "      <td>0.067664</td>\n",
       "      <td>0.473973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.754265</td>\n",
       "      <td>0.080136</td>\n",
       "      <td>0.439883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.645866</td>\n",
       "      <td>0.389442</td>\n",
       "      <td>0.582857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.006645</td>\n",
       "      <td>0.047157</td>\n",
       "      <td>0.322667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.878003</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>0.479784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.643804</td>\n",
       "      <td>-0.009418</td>\n",
       "      <td>0.063158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.789995</td>\n",
       "      <td>0.025566</td>\n",
       "      <td>0.069930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set      RMSE     Kappa  Accuracy\n",
       "0        1.0  1.435308  0.053484  0.254098\n",
       "1        2.0  0.889821  0.067664  0.473973\n",
       "2        3.0  0.754265  0.080136  0.439883\n",
       "3        4.0  0.645866  0.389442  0.582857\n",
       "4        5.0  1.006645  0.047157  0.322667\n",
       "5        6.0  0.878003  0.077162  0.479784\n",
       "6        7.0  4.643804 -0.009418  0.063158\n",
       "7        8.0  4.789995  0.025566  0.069930"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_set_results = essay_set_metrics(cnn_test_df)\n",
    "essay_set_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "147120/147120 [==============================] - 409s 3ms/step - loss: 0.0301 - acc: 0.0991\n",
      "Epoch 2/20\n",
      "147120/147120 [==============================] - 393s 3ms/step - loss: 0.0281 - acc: 0.0999\n",
      "Epoch 3/20\n",
      "147120/147120 [==============================] - 383s 3ms/step - loss: 0.0272 - acc: 0.1004\n",
      "Epoch 4/20\n",
      "147120/147120 [==============================] - 379s 3ms/step - loss: 0.0264 - acc: 0.1009\n",
      "Epoch 5/20\n",
      "102000/147120 [===================>..........] - ETA: 1:57 - loss: 0.0256 - acc: 0.1012"
     ]
    }
   ],
   "source": [
    "estimator_lstm = KerasRegressor(build_fn=stack_lstm, epochs=20, batch_size=50)\n",
    "estimator_lstm.fit(train_data, train_y_sentence)\n",
    "prediction_lstm=estimator_lstm.predict(test_data)\n",
    "rmse_val_lstm = RMSE(test_y_sentence,prediction_lstm)\n",
    "print(\"RMSE: \",rmse_val_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNN_Glove</th>\n",
       "      <th>Stacked LSTM</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.692931</td>\n",
       "      <td>0.723046</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.702375</td>\n",
       "      <td>0.678391</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798613</td>\n",
       "      <td>0.734653</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.703292</td>\n",
       "      <td>0.677914</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.671944</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.747734</td>\n",
       "      <td>0.820812</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.677340</td>\n",
       "      <td>0.650709</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.616736</td>\n",
       "      <td>0.506052</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.732711</td>\n",
       "      <td>0.706890</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.828496</td>\n",
       "      <td>0.792971</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNN_Glove  Stacked LSTM  Actual\n",
       "0   0.692931      0.723046    0.60\n",
       "1   0.702375      0.678391    0.60\n",
       "2   0.798613      0.734653    0.78\n",
       "3   0.703292      0.677914    0.80\n",
       "4   0.671944      0.669563    0.52\n",
       "5   0.747734      0.820812    0.50\n",
       "6   0.677340      0.650709    0.75\n",
       "7   0.616736      0.506052    0.75\n",
       "8   0.732711      0.706890    0.75\n",
       "9   0.828496      0.792971    1.00"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df = pd.DataFrame([prediction.astype(np.double), prediction_lstm.astype(np.double), test_y_sentence.astype(np.double)]).transpose()\n",
    "cnn_df.columns = ['CNN_Glove','Stacked LSTM','Actual']\n",
    "cnn_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen Kappa:  0.15593670766702683\n"
     ]
    }
   ],
   "source": [
    "c_kappa = CohenKappa(test_y_sentence,cnn_glove_predict)\n",
    "print(\"Cohen Kappa: \",c_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen Kappa LSTM:  0.14598100325900654\n"
     ]
    }
   ],
   "source": [
    "c_kappa = CohenKappa(test_y_sentence,prediction_lstm)\n",
    "print(\"Cohen Kappa LSTM: \",c_kappa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
