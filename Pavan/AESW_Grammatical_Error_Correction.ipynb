{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import json, os, re, shutil, sys, time\n",
    "import seaborn as sns\n",
    "from importlib import reload\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "from collections import defaultdict\n",
    "import xmltodict\n",
    "import untangle\n",
    "import xml.etree.ElementTree as ET\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Import spacy\n",
    "import spacy\n",
    "\n",
    "# NumPy, Pandas and TensorFlow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import CONTRACTION_MAP\n",
    "import unicodedata\n",
    "\n",
    "from numpy.random import seed\n",
    "from pandas import read_csv, DataFrame\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "## Plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get AESW train Data. It is in XML\n",
    "tree = ET.parse('../data-DNC/AESW/aesw2016_v1.2_train.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary which has sentence ID as key, and the sentence as value\n",
    "sent_dict = dict()\n",
    "for sent in root.iter('sentence'):\n",
    "    sid = sent.attrib['sid']\n",
    "    sent_dict[sid]=sent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189412"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>To facilitate an easier notation throughout t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>To facilitate an easier notation throughout t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Therefore MATH defines a special order of tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>This is important since only MATH is the real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Note that in all contour time-integrals we es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1                                                  2\n",
       "0  1  1.0   To facilitate an easier notation throughout t...\n",
       "1 -1  1.0   To facilitate an easier notation throughout t...\n",
       "2  0  1.1   Therefore MATH defines a special order of tim...\n",
       "3  0  1.2   This is important since only MATH is the real...\n",
       "4  0  1.3   Note that in all contour time-integrals we es..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us load the tok file which is in tsv format.\n",
    "aesw_train_labels = pd.read_csv(\"../data-DNC/AESW/aesw2016_v1.2_train.tok\",sep='\\t',encoding = \"latin1\",header=None)\n",
    "aesw_train_labels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that token file is sufficient for us as it contains sentences and their correction. We do not need the xml file anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1196903"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change column names\n",
    "aesw_train_labels.columns = ['Key_ID','Sent_ID','Text']\n",
    "\n",
    "# Key_ID of 1 indicates corrected sentence, and -1 is pre-corrected. 0 means no grammatical error\n",
    "# We can get rid of corrected sentence, as we are not looking for particulars of grammar.\n",
    "# Just a binary classification of error or not is sufficient.\n",
    "\n",
    "aesw_train_labels = aesw_train_labels[aesw_train_labels.Key_ID!=1]\n",
    "len(aesw_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the key_id of error sentences to \"1\" instead of \"-1\"\n",
    "mask = aesw_train_labels.Key_ID == -1\n",
    "column_name = 'Key_ID'\n",
    "aesw_train_labels.loc[mask, column_name] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>To facilitate an easier notation throughout t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Therefore MATH defines a special order of tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>This is important since only MATH is the real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Note that in all contour time-integrals we es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Theorem REF proves the equivalence of ensembl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Set the magnetic field MATH , call MATH the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>We claim that MATHDISP where , as before , MA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>In fact by the general theory after the limit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Inspired by Clegg -LRB- 2002 -RRB- , the benc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>It can be concluded that , usually , calculat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Key_ID  Sent_ID                                               Text\n",
       "1        1      1.0   To facilitate an easier notation throughout t...\n",
       "2        0      1.1   Therefore MATH defines a special order of tim...\n",
       "3        0      1.2   This is important since only MATH is the real...\n",
       "4        0      1.3   Note that in all contour time-integrals we es...\n",
       "5        0      2.0   Theorem REF proves the equivalence of ensembl...\n",
       "6        0      2.1   Set the magnetic field MATH , call MATH the f...\n",
       "8        1      2.2   We claim that MATHDISP where , as before , MA...\n",
       "10       1      2.3   In fact by the general theory after the limit...\n",
       "12       1      3.0   Inspired by Clegg -LRB- 2002 -RRB- , the benc...\n",
       "13       0      3.1   It can be concluded that , usually , calculat..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify if we have only the error and non-error sentences\n",
    "aesw_train_labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training data into x and y (labels)\n",
    "x_train = aesw_train_labels.Text.as_matrix(columns=None)\n",
    "y_train = aesw_train_labels.Key_ID.as_matrix(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The team of robots in Chapter REF and CITE cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>The Hamiltonian -LRB- Lyapunov function -RRB-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Therefore , for MATH robots the time derivati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>The estimator/guidance algorithm for finding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>The feedback controller is MATHDISP and the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Key_ID  Sent_ID                                               Text\n",
       "0       0      1.0   The team of robots in Chapter REF and CITE cr...\n",
       "2       1      1.1   The Hamiltonian -LRB- Lyapunov function -RRB-...\n",
       "4       1      1.2   Therefore , for MATH robots the time derivati...\n",
       "5       0      1.3   The estimator/guidance algorithm for finding ...\n",
       "7       1      1.4   The feedback controller is MATHDISP and the s..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat the procedure for dev data\n",
    "aesw_dev_labels = pd.read_csv(\"../data-DNC/AESW/aesw2016_v1.2_dev.tok\",sep='\\t',encoding = \"latin1\",header=None)\n",
    "aesw_dev_labels.columns = ['Key_ID','Sent_ID','Text']\n",
    "aesw_dev_labels = aesw_dev_labels[aesw_dev_labels.Key_ID!=1]\n",
    "mask = aesw_dev_labels.Key_ID == -1\n",
    "column_name = 'Key_ID'\n",
    "aesw_dev_labels.loc[mask, column_name] = 1\n",
    "x_dev = aesw_dev_labels.Text.as_matrix(columns=None)\n",
    "y_dev = aesw_dev_labels.Key_ID.as_matrix(columns=None)\n",
    "aesw_dev_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use Keras Tokenizer to tokenize train data\n",
    "vocabulary_size = 50000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will pad the sequences to the max length of the sentence.\n",
    "# Later on, we will try with limiting the padding to max_len of 50\n",
    "train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "train_data = pad_sequences(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = train_data.shape[1]\n",
    "print(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148409, 271)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat the same for dev data\n",
    "dev_seq = tokenizer.texts_to_sequences(x_dev)\n",
    "dev_data = pad_sequences(dev_seq, maxlen=max_seq_len)\n",
    "dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply simple CNN based binary classification\n",
    "seed(2017)\n",
    "conv = Sequential()\n",
    "conv.add(Embedding(vocabulary_size, 100, input_length=max_seq_len))\n",
    "conv.add(Conv1D(64, 5, activation = 'relu'))\n",
    "conv.add(MaxPooling1D(2))\n",
    "conv.add(Flatten())\n",
    "conv.add(Dense(1, activation = 'sigmoid'))\n",
    "sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "conv.compile(loss = 'binary_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "conv.fit(train_data, y_train, batch_size = 500, epochs = 8, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = conv.predict(dev_data)\n",
    "pred_labels = (pred > 0.5).astype(np.int)\n",
    "pred_labels = np.reshape(pred_labels,[dev_data.shape[0],])\n",
    "\n",
    "#print(y_dev[0:5])\n",
    "#print(pred_labels[0:5])\n",
    "accuracy = accuracy_score(y_dev,pred_labels)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use GloVe embeddings instead of trained embedding layer\n",
    "embeddings_index = dict()\n",
    "f = open('/Users/kurapati/W266/data/glove.42B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocabulary_size, 300))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat the CNN layer, but with GloVe embedding\n",
    "seed(2018)\n",
    "conv_glove = Sequential()\n",
    "conv_glove.add(Embedding(vocabulary_size, 300, input_length=50, weights=[embedding_matrix], trainable=False))\n",
    "conv_glove.add(Conv1D(64, 5, activation = 'relu'))\n",
    "conv_glove.add(MaxPooling1D(4))\n",
    "conv_glove.add(Flatten())\n",
    "conv_glove.add(Dense(1, activation = 'sigmoid'))\n",
    "sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "conv_glove.compile(loss = 'binary_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "conv_glove.fit(data, y_train, batch_size = 500, epochs = 8, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = conv_glove.predict(dev_data)\n",
    "pred_labels = (pred > 0.5).astype(np.int)\n",
    "pred_labels = np.reshape(pred_labels,[148409,])\n",
    "\n",
    "#print(y_dev[0:5])\n",
    "#print(pred_labels[0:5])\n",
    "accuracy = accuracy_score(y_dev,pred_labels)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With CNN and LSTM\n",
    "seed(2018)\n",
    "conv_glove = Sequential()\n",
    "conv_glove.add(Embedding(vocabulary_size, 300, input_length=50, weights=[embedding_matrix], trainable=False))\n",
    "conv_glove.add(Conv1D(64, 5, activation = 'relu'))\n",
    "conv_glove.add(MaxPooling1D(4))\n",
    "conv_glove.add(LSTM(100))\n",
    "conv_glove.add(Dense(1, activation = 'sigmoid'))\n",
    "sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "conv_glove.compile(loss = 'binary_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "conv_glove.fit(data, y_train, batch_size = 500, epochs = 8, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = conv_glove.predict(dev_data)\n",
    "pred_labels = (pred > 0.5).astype(np.int)\n",
    "pred_labels = np.reshape(pred_labels,[148409,])\n",
    "\n",
    "#print(y_dev[0:5])\n",
    "#print(pred_labels[0:5])\n",
    "accuracy = accuracy_score(y_dev,pred_labels)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F1 score\n",
    "cnn_glove_f1 = f1_score(y_dev,pred_labels)\n",
    "print(\"F1: \",cnn_glove_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_precision = average_precision_score(y_dev,pred_labels)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
